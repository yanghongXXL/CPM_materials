[{"path":"index.html","id":"关于课程","chapter":"关于课程","heading":"关于课程","text":"","code":""},{"path":"index.html","id":"课程目标","chapter":"关于课程","heading":"课程目标","text":"了解临床预测模型相关概念与构建流程了解临床预测模型相关概念与构建流程了解Python与R语言基本使用与案例实操了解Python与R语言基本使用与案例实操了解MIMIC与NHANES公共数据库了解MIMIC与NHANES公共数据库","code":""},{"path":"index.html","id":"课程大纲","chapter":"关于课程","heading":"课程大纲","text":"","code":""},{"path":"index.html","id":"案例教学","chapter":"关于课程","heading":"案例教学","text":"临床预测模型概述\n应用场景\n模型构建流程\n模型报告\n传统统计与机器学习\n应用场景应用场景模型构建流程模型构建流程模型报告模型报告传统统计与机器学习传统统计与机器学习案例介绍\n案例背景\n数据描述\n分析思路\n代码预览\n案例背景案例背景数据描述数据描述分析思路分析思路代码预览代码预览","code":""},{"path":"index.html","id":"实操教学","chapter":"关于课程","heading":"实操教学","text":"Anaconda安装与包的安装\n如何打开.ipynb文件\nAnaconda Prompt 基本命令\n使用conda或pip安装包\nAnaconda安装与包的安装如何打开.ipynb文件如何打开.ipynb文件Anaconda Prompt 基本命令Anaconda Prompt 基本命令使用conda或pip安装包使用conda或pip安装包Python入门基础\n数据读取\n模型构建等基础语法\n案例实操：代码与对应结果详细解释\n数据描述\n数据预处理\n模型构建\n\nPython入门基础数据读取数据读取模型构建等基础语法模型构建等基础语法案例实操：代码与对应结果详细解释\n数据描述\n数据预处理\n模型构建\n案例实操：代码与对应结果详细解释数据描述数据描述数据预处理数据预处理模型构建模型构建R安装与入门\n数据读取\n模型构建等基础语法\n案例实操：代码与对应结果详细解释\nR安装与入门数据读取数据读取模型构建等基础语法模型构建等基础语法案例实操：代码与对应结果详细解释案例实操：代码与对应结果详细解释NHANES数据库简介、数据提取NHANES数据库简介、数据提取MIMIC IV 数据库简介、申请、安装、提取MIMIC IV 数据库简介、申请、安装、提取","code":""},{"path":"index.html","id":"上课要求","chapter":"关于课程","heading":"上课要求","text":"自带电脑（课程以windows系统为例）自带电脑（课程以windows系统为例）软件安装、代码运行实操软件安装、代码运行实操","code":""},{"path":"index.html","id":"如何提问","chapter":"关于课程","heading":"如何提问","text":"鼓励先自己动手查询（baidu、biying、github、CSDN）鼓励先自己动手查询（baidu、biying、github、CSDN）想获得快速帮助，请描述以下内容（问题截全图）\n想解决的问题是什么？\n代码是什么？\n报错信息是什么？\n想获得快速帮助，请描述以下内容（问题截全图）想解决的问题是什么？想解决的问题是什么？代码是什么？代码是什么？报错信息是什么？报错信息是什么？","code":""},{"path":"index.html","id":"课程用到的软件","chapter":"关于课程","heading":"课程用到的软件","text":"AnacondaR、RstudioPostgresql、Navicat、7z","code":""},{"path":"index.html","id":"需要安装的包","chapter":"关于课程","heading":"需要安装的包","text":"Python或者缺少什么包安装什么包R或者缺少什么包安装什么包","code":"pip install scikit-learn\npip install pandas_profiling\npip install matplotlibconda install 包名\nmy_packages <- \n   c(\"tidyverse\", \"dlookr\", \"plotROC\", \"pROC\", \"e1071\", \"caret\",\n     \"ggplot2\", \"rms\", \"regplot\",\"nhanesA\", \"haven\",\"glmnet\")\ninstall.packages(my_packages, dependencies = T)\n\nfor (pkg in my_packages)\n{\n  if (!require(pkg, character.only = TRUE)) {\n    install.packages(pkg)\n  }\n}\ninstall.packages(\"包名\")"},{"path":"案例教学-1.html","id":"案例教学-1","chapter":"案例教学","heading":"案例教学","text":"","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"健康医疗大数据驱动下的临床科研","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"第 1 部分 健康医疗大数据驱动下的临床科研","text":"","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"健康医疗大数据驱动下的临床科研-1","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.1 健康医疗大数据驱动下的临床科研","text":"","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"医疗大数据及其应用","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.1.1 医疗大数据及其应用","text":"什么是大数据大数据（Big data）是结构化和非结构化数据集的广义术语，既庞大又复杂，以至于传统的数据处理应用程序和系统无法充分处理它们。健康医疗大数据为疾病人工智能诊断与预测预后分析提供强大支撑。医疗大数据的特点医疗大数据的应用","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"疾病模型类型","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.1.2 疾病模型类型","text":"疾病的全周期模型类型","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"研究设计类型","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.1.3 研究设计类型","text":"研究设计方法临床研究五要素（PiCOT）","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"临床数据获取","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.1.4 临床数据获取","text":"数据的获取与处理数据的集成和整合全过程分析CRF表的制定设计要点科学性：每个问题都要真实、可靠地测量研究人群的属性、特征、知识、态度或行为科学性：每个问题都要真实、可靠地测量研究人群的属性、特征、知识、态度或行为逻辑性：逻辑结构自然、顺畅，问题之间的逻辑关系较强逻辑性：逻辑结构自然、顺畅，问题之间的逻辑关系较强易用性：易于被研究对象和调查员理解和接受易用性：易于被研究对象和调查员理解和接受COPD-CRF基线部分（例）COPD-CRF随访部分（例）","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"变量类型与筛选","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.1.5 变量类型与筛选","text":"变量角色预测变量/自变量选择指标组合的建模方法\nC模型：基于临床特征（Clinic character/history）：如来自HIS、LIS系统的数据、非结构化数据的量化与建模，如心电图、彩超、影像数据等\nBC模型：基于临床特征+ 生物标志物（ Biomarker）的预后模型\nABC模型：基于临床特征 + 生物标志物 +人口学（或一般情况）的预后模型\n指标组合的建模方法C模型：基于临床特征（Clinic character/history）：如来自HIS、LIS系统的数据、非结构化数据的量化与建模，如心电图、彩超、影像数据等C模型：基于临床特征（Clinic character/history）：如来自HIS、LIS系统的数据、非结构化数据的量化与建模，如心电图、彩超、影像数据等BC模型：基于临床特征+ 生物标志物（ Biomarker）的预后模型BC模型：基于临床特征+ 生物标志物（ Biomarker）的预后模型ABC模型：基于临床特征 + 生物标志物 +人口学（或一般情况）的预后模型ABC模型：基于临床特征 + 生物标志物 +人口学（或一般情况）的预后模型生命质量或患者报告结局（PRO）生命质量或患者报告结局（PRO）结局变量选择","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"临床预测模型","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2 临床预测模型","text":"当今医学从经验医学发展到循证医学，再到精准医学，临床数据的应用也随着大数据时代的来临越来越受到重视。循证医学缺点：①降低了疾病深层机制和特殊人群特点的影响权重，将导致普遍性与特殊性之间的巨大偏差；②高质量的循证研究费时费力(各种RCT)。精准医学克服循证医学一些系统性的劣势。临床预测模型就是在精准医学研究思维模式的基础上应运而生，成为当下最炙手可热的临床领域之一。在PubMed以”Clinical Prediction Model” 搜索，自1964年发表的第一篇文章以来，到2015年论文发表数量以极快的趋势增长，其火热程度可见一斑。","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"临床预测模型应用场景","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.1 临床预测模型应用场景","text":"","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"什么是临床预测模型","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.1.1 什么是临床预测模型？","text":"预测模型\n数学方程（数理）\n回归模型（统计）\n算法（计算机）\n规则（普通）\n预测模型数学方程（数理）数学方程（数理）回归模型（统计）回归模型（统计）算法（计算机）算法（计算机）规则（普通）规则（普通）临床预测模型\n应用与临床\n针对个体患者\n结局预测\n医学事件：死亡、再住院、复发等\n结局值：住院天数、住院费用\n\n临床预测模型应用与临床应用与临床针对个体患者针对个体患者结局预测\n医学事件：死亡、再住院、复发等\n结局值：住院天数、住院费用\n结局预测医学事件：死亡、再住院、复发等医学事件：死亡、再住院、复发等结局值：住院天数、住院费用结局值：住院天数、住院费用临床预测模型(Clinical Prediction Models)\n是指利用多因素模型估算患有某病的概率或者将来某结局发生的概率。临床预测模型(Clinical Prediction Models)是指利用多因素模型估算患有某病的概率或者将来某结局发生的概率。","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"应用场景","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.1.2 应用场景","text":"临床预测模型的应用场景主要是临床，针对个体患者，进行结局预测，例如预测医学事件：某种疾病的发生率、复发率、伤残率、并发症的发生以及死亡率等，也可以用于预测结局值：住院天数、住院费用等。临床领域的应用\n预测急性心肌梗死患者30天的死亡率\n新型抗癌药物在某种癌症患者中的有效率\n新冠肺炎患者转为危重症的发生概率\n判断咳嗽患者发生哮喘的概率\n临床领域的应用预测急性心肌梗死患者30天的死亡率预测急性心肌梗死患者30天的死亡率新型抗癌药物在某种癌症患者中的有效率新型抗癌药物在某种癌症患者中的有效率新冠肺炎患者转为危重症的发生概率新冠肺炎患者转为危重症的发生概率判断咳嗽患者发生哮喘的概率判断咳嗽患者发生哮喘的概率应用价值\n量化对患者预测的结果\n更直观地展示疾病的危险性和治疗方案一定程度上缓和了医患之间信息不对称\n应用价值量化对患者预测的结果量化对患者预测的结果更直观地展示疾病的危险性和治疗方案一定程度上缓和了医患之间信息不对称更直观地展示疾病的危险性和治疗方案一定程度上缓和了医患之间信息不对称公共卫生领域（三级预防体系中发挥作用）\n根据特定人群的健康状态，量化未来患病的概率\n构建高灵敏度和特异度的诊断模型\n利用预后模型对疾病的复发、死亡、伤残以及出现并发症的概率进行预测\n公共卫生领域（三级预防体系中发挥作用）根据特定人群的健康状态，量化未来患病的概率根据特定人群的健康状态，量化未来患病的概率构建高灵敏度和特异度的诊断模型构建高灵敏度和特异度的诊断模型利用预后模型对疾病的复发、死亡、伤残以及出现并发症的概率进行预测利用预后模型对疾病的复发、死亡、伤残以及出现并发症的概率进行预测实现价值\n为健康教育和行为干预提供直观参考\n将无创痛、经济性、便利性的指标用于疾病筛查，实现“早发现、早诊断、早治疗”的二级预防\n指导个体化治疗和康复方案的制定，防止病情恶化，预防并发症和伤残，提高患者生存质量\n实现价值为健康教育和行为干预提供直观参考为健康教育和行为干预提供直观参考将无创痛、经济性、便利性的指标用于疾病筛查，实现“早发现、早诊断、早治疗”的二级预防将无创痛、经济性、便利性的指标用于疾病筛查，实现“早发现、早诊断、早治疗”的二级预防指导个体化治疗和康复方案的制定，防止病情恶化，预防并发症和伤残，提高患者生存质量指导个体化治疗和康复方案的制定，防止病情恶化，预防并发症和伤残，提高患者生存质量","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"为什么做临床预测模型","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.1.3 为什么做临床预测模型？","text":"临床医生可能常常面临这样的困惑：①患者询问医生，体检发现血脂高，未来十年得冠心病的可能性是多少？需不需要吃药？②慢乙肝免疫耐受期患者抗不抗病毒？现在治疗和延迟治疗哪个更好？哪个花钱多？③如果能提前预测患者的病情，比如提前预测肝癌患者是否有微血管浸润，可能有助于外科医生在标准切除和扩大切除这两个完全不同的切除方式之间作出选择，患者结局或许不同。临床预测模型就可以解答这些困惑。临床预测模型具有两方面的意义：一方面是临床价值，借助临床预测模型，医生可以更精准地做出临床决策，帮助患者实现更有利的价值选择，卫生管理部门可以更合理地配置医疗资源；另一方面是对医生发展的影响，临床预测模型目前已成为SCI期刊发表论文的热门，更是SCI高分期刊的宠儿，通过收集数据，构建临床预测模型，能够快速地发表学术论文，提升职称，完成医生的高级进阶。","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"临床预测模型怎么构建","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.2 临床预测模型怎么构建","text":"","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"完整构建流程","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.2.1 完整构建流程","text":"","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"确定研究问题和预测模型类型","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.2.2 确定研究问题和预测模型类型","text":"最常见的两种类型诊断模型：\n主要是基于研究对象的临床特征，预测当前患有某种疾病的概率，多见于横断面研究;诊断模型：主要是基于研究对象的临床特征，预测当前患有某种疾病的概率，多见于横断面研究;预后模型：\n是研究对象在患某种疾病时，预测其未来疾病的复发、死亡、伤残等转归情况的概率，多见于纵向研究，如队列研究等。预后模型：是研究对象在患某种疾病时，预测其未来疾病的复发、死亡、伤残等转归情况的概率，多见于纵向研究，如队列研究等。预测模型的类型取决于感兴趣的结局结局类型：\n分类变量？ -> 二分类？多分类？\n连续变量？\n有无考虑”生存时间”？\n结局类型：分类变量？ -> 二分类？多分类？分类变量？ -> 二分类？多分类？连续变量？连续变量？有无考虑”生存时间”？有无考虑”生存时间”？不同结局类型确定选用的模型 ——> 数据决定模型","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"数据的预处理","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.2.3 数据的预处理","text":"数据的收集：现有的试验、队列研究、登记注册或管理的数据集\n数据集中样本量越大、患者信息越多，构建的预测模型就越准确\n\n注意：数据预处理前做好数据”整洁” 避免”脏”数据！\n数据的收集：现有的试验、队列研究、登记注册或管理的数据集数据集中样本量越大、患者信息越多，构建的预测模型就越准确注意：数据预处理前做好数据”整洁” 避免”脏”数据！“整洁”数据：一行是一个样本所有信息一行是一个样本所有信息一列是一个variable一列是一个variable中间无乱码、不规范表达中间无乱码、不规范表达“脏”数据：变量名不规范变量名不规范数值中英文混杂数值中英文混杂标点符号标点符号数据预处理：\n离群值、异常值\n缺失值：删除？填补？\n协变量的类型\n连续变量\n分类、有序多分类、无序多分类\n\n协变量的编码与转换\none-hot encoding\nLeave-one-\n对数转化等（参考知乎讨论）\n\n数据预处理：离群值、异常值离群值、异常值缺失值：删除？填补？缺失值：删除？填补？协变量的类型\n连续变量\n分类、有序多分类、无序多分类\n协变量的类型连续变量连续变量分类、有序多分类、无序多分类分类、有序多分类、无序多分类协变量的编码与转换\none-hot encoding\nLeave-one-\n对数转化等（参考知乎讨论）\n协变量的编码与转换one-hot encodingone-hot encodingLeave-one-outLeave-one-out对数转化等（参考知乎讨论）对数转化等（参考知乎讨论）","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"变量筛选","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.2.4 变量筛选","text":"","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"模型的选择","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.2.5 模型的选择","text":"传统模型梳理机器学习类型","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"模型的构建","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.2.6 模型的构建","text":"","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"模型的评价","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.2.7 模型的评价","text":"常用概率解释\n假阳率：模型预测为正例实际负例的样本\nFalse Positive Rate = 实负测正 / 实负 = FP / (FP + TN)\n假阴率：模型预测为负例实际为正例的样本\nFalse Negative Rate = 实正测负 / 实正 = FN / (TP + FN)\n真阳率：模型预测为正例实际为正例的样本\nTrue Positive Rate = 实正测正 / 实正 = TP / (TP + FN)\n真阴率：模型预测为负例实际为负例的样本\nTrue Negative Rate = 实负测负 / 实负 = TN / (FP + TN)\n常用概率解释假阳率：模型预测为正例实际负例的样本\nFalse Positive Rate = 实负测正 / 实负 = FP / (FP + TN)假阳率：模型预测为正例实际负例的样本False Positive Rate = 实负测正 / 实负 = FP / (FP + TN)假阴率：模型预测为负例实际为正例的样本\nFalse Negative Rate = 实正测负 / 实正 = FN / (TP + FN)假阴率：模型预测为负例实际为正例的样本False Negative Rate = 实正测负 / 实正 = FN / (TP + FN)真阳率：模型预测为正例实际为正例的样本\nTrue Positive Rate = 实正测正 / 实正 = TP / (TP + FN)真阳率：模型预测为正例实际为正例的样本True Positive Rate = 实正测正 / 实正 = TP / (TP + FN)真阴率：模型预测为负例实际为负例的样本\nTrue Negative Rate = 实负测负 / 实负 = TN / (FP + TN)真阴率：模型预测为负例实际为负例的样本True Negative Rate = 实负测负 / 实负 = TN / (FP + TN)分类结果混淆矩分类结果混淆矩常用指标\n准确率（Accuracy）\n正例和负例中分别被正确预测的样本数量占总样本数量的比例\nAUC\n表示ROC曲线下的面积，即ROC曲线与x轴、（1，0）-（1，1）围绕的面积，评估的是随机给定一个正例和一个负例，模型对正例的预测概率大于模型对于负例预测概率的概率。\n召回率（Recall）\n以实际样本为基础，实际样本为正例，被模型预测正确的正例占总体实际样本正例的比例。\n精确度（Pecision）\n以预测结果为基础，被模型预测为正例的样本中是正确的比例。预测为正例的结果分两种，要么实际是正例TP，要么实际是负例FP。\nF1 score\n精确度和召回率是一对矛盾的度量，一般来说，精确度高时，召回率值往往偏低；而精确度值低时，召回率值往往偏高。当分类置信度高时，精确度偏高；分类置信度低时，召回率偏高。为了能够综合考虑这两个指标，F1 score被提出。\n……\n常用指标准确率（Accuracy）\n正例和负例中分别被正确预测的样本数量占总样本数量的比例准确率（Accuracy）正例和负例中分别被正确预测的样本数量占总样本数量的比例AUC\n表示ROC曲线下的面积，即ROC曲线与x轴、（1，0）-（1，1）围绕的面积，评估的是随机给定一个正例和一个负例，模型对正例的预测概率大于模型对于负例预测概率的概率。AUC表示ROC曲线下的面积，即ROC曲线与x轴、（1，0）-（1，1）围绕的面积，评估的是随机给定一个正例和一个负例，模型对正例的预测概率大于模型对于负例预测概率的概率。召回率（Recall）\n以实际样本为基础，实际样本为正例，被模型预测正确的正例占总体实际样本正例的比例。召回率（Recall）以实际样本为基础，实际样本为正例，被模型预测正确的正例占总体实际样本正例的比例。精确度（Pecision）\n以预测结果为基础，被模型预测为正例的样本中是正确的比例。预测为正例的结果分两种，要么实际是正例TP，要么实际是负例FP。精确度（Pecision）以预测结果为基础，被模型预测为正例的样本中是正确的比例。预测为正例的结果分两种，要么实际是正例TP，要么实际是负例FP。F1 score\n精确度和召回率是一对矛盾的度量，一般来说，精确度高时，召回率值往往偏低；而精确度值低时，召回率值往往偏高。当分类置信度高时，精确度偏高；分类置信度低时，召回率偏高。为了能够综合考虑这两个指标，F1 score被提出。F1 score精确度和召回率是一对矛盾的度量，一般来说，精确度高时，召回率值往往偏低；而精确度值低时，召回率值往往偏高。当分类置信度高时，精确度偏高；分类置信度低时，召回率偏高。为了能够综合考虑这两个指标，F1 score被提出。…………Diagnostic testingDiagnostic testing","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"模型的展示","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.2.8 模型的展示","text":"应用程序网页应用程序网页NomogramNomogram评分系统评分系统彩色打分卡彩色打分卡应用程序网页Nomogram评分系统彩色打分卡结果快速精确可嵌入常规诊疗系统无需电子设备只需简单加法连续变量需切割结果不精确连续变量需切割结果不精确预测因子不能太多","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"模型报告","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.3 模型报告","text":"只有对预测模型各方面的信息进行全面和明确的报告，才能充分评估预测模型的偏倚风险和潜在有用性。个体预后或诊断多变量预测模型透明报告Transparent Reporting multivariable prediction model Individual Prognosis Diagnosis (TRIPOD)为开发、验证或更新预测模型的研究报告提出了一套建议。","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"临床预测模型报告规范tripod","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.3.1 临床预测模型报告规范（TRIPOD）","text":"TRIPOD条目解读","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"临床预测模型指南","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.3.2 临床预测模型指南","text":"","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"研究设计和方法学评价probast","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.3.3 研究设计和方法学评价：PROBAST","text":"机器学习构建流程总结","code":""},{"path":"健康医疗大数据驱动下的临床科研.html","id":"机器学习-vs-传统统计","chapter":"第 1 部分 健康医疗大数据驱动下的临床科研","heading":"1.2.4 机器学习 VS 传统统计","text":"","code":""},{"path":"案例介绍.html","id":"案例介绍","chapter":"第 2 部分 案例介绍","heading":"第 2 部分 案例介绍","text":"","code":""},{"path":"案例介绍.html","id":"案例背景","chapter":"第 2 部分 案例介绍","heading":"2.1 案例背景","text":"","code":""},{"path":"案例介绍.html","id":"数据来源","chapter":"第 2 部分 案例介绍","heading":"2.1.1 数据来源","text":"案例选自UCI机器学习库中的 Heart Disease Data Set数据集。该数据库包含76个属性，但是所有已发布的实验都引用了其中14个属性的子集。特别是，克利夫兰数据库是迄今为止ML研究人员使用的唯一数据库。数据来源：https://archive.ics.uci.edu/ml/datasets/Heart+Disease","code":""},{"path":"案例介绍.html","id":"疾病背景","chapter":"第 2 部分 案例介绍","heading":"2.1.2 疾病背景","text":"冠心病（Coronary Heart Disease,CHD）心血管疾病是全球第一大死亡原因，每年夺去约1790万人的生命，占全球死亡人数的31%。5例心血管疾病中有4例死于心脏病和中风，其中1 / 3的死亡发生在70岁以下的过早死亡中。患有心血管疾病或心血管风险高的人(由于存在高血压、糖尿病、高脂血症或已经确定的疾病等一种或多种风险因素)需要早期检测和管理，其中机器学习模型可以提供很大的帮助。目前把冠心病分类两大类：\n① 急性冠脉综合征：\n不稳定型心绞痛（UA）；非ST段抬高性心肌梗死（NSTEMI）；ST段抬高性心肌梗死（STEMI）\n② 慢性冠脉综合征：\n慢性稳定型心绞痛；冠脉正常的心绞痛（如X综合征）；无症状性心肌缺血；缺血性心力衰竭；目前把冠心病分类两大类：① 急性冠脉综合征：不稳定型心绞痛（UA）；非ST段抬高性心肌梗死（NSTEMI）；ST段抬高性心肌梗死（STEMI）② 慢性冠脉综合征：慢性稳定型心绞痛；冠脉正常的心绞痛（如X综合征）；无症状性心肌缺血；缺血性心力衰竭；冠心病有”5+3”危险因素：\n① 五种可防可控的危险因素：\n高血压；血脂异常；糖尿病以及糖耐量的异常；吸烟；肥胖\n② 三种不可防不可控的危险因素：\n性别；年龄；家族史冠心病有”5+3”危险因素：① 五种可防可控的危险因素：高血压；血脂异常；糖尿病以及糖耐量的异常；吸烟；肥胖② 三种不可防不可控的危险因素：性别；年龄；家族史目前，冠心病的诊断流程极其繁琐：\n① 怀疑冠心病的患者最开始可能会安排这3项检查：常规心电图、超声心动图和血液的心肌标志物检查；\n② 上述检查后如果没有查出明显病变，但是患者仍有冠心病相关症状的话，医生可能会安排进行运动负荷试验或动态心电图检查；\n③ 进行完基础检查后如果怀疑患者冠心病的可能性极大，医生可能会建议进行CTA或心肌血流灌注检查；\n④ 也有些医生会直接建议患者进行心脏冠状动脉造影检查，因为冠状动脉造影检查是诊断冠心病最准确的办法；目前，冠心病的诊断流程极其繁琐：① 怀疑冠心病的患者最开始可能会安排这3项检查：常规心电图、超声心动图和血液的心肌标志物检查；② 上述检查后如果没有查出明显病变，但是患者仍有冠心病相关症状的话，医生可能会安排进行运动负荷试验或动态心电图检查；③ 进行完基础检查后如果怀疑患者冠心病的可能性极大，医生可能会建议进行CTA或心肌血流灌注检查；④ 也有些医生会直接建议患者进行心脏冠状动脉造影检查，因为冠状动脉造影检查是诊断冠心病最准确的办法；在本项研究中，研究者负责分析导致患者的冠心病的因素，并探索各个变量的影响程度。他们希望能够通过有效的机器学习算法构建模型，用于预测患者是否有冠心病。","code":""},{"path":"案例介绍.html","id":"研究目的","chapter":"第 2 部分 案例介绍","heading":"2.1.3 研究目的","text":"如何快速准确判断患者是否有冠心病？如何快速准确判断患者是否有冠心病？影响冠心病的危险因素有哪些？影响冠心病的危险因素有哪些？","code":""},{"path":"案例介绍.html","id":"数据描述","chapter":"第 2 部分 案例介绍","heading":"2.2 数据描述","text":"数据展示（选取前10行）数据集变量信息303个受试者（行：Sample）;14列变量属性(列：Feature)；变量属性包括：年龄、性别、胸痛经历、静息血压、胆固醇、空腹血糖、静息心电图、最大心率、运动引起的 ST 压低、峰值运动ST段的斜率、运动诱发的心绞痛、主要供血血管的数量、地中海贫血、心脏病这些变量包括以下几类：① 不可改变的危险因素：年龄、性别、家族史（收集了地中海贫血）② 可改变的危险因素：静息血压、胆固醇、空腹血糖③ 临床检查：心电图相关、运动触发相关、冠脉检查相关","code":"## Rows: 303\n## Columns: 14\n## $ age      <dbl> 63, 53, 41, 56, 60, 57, 56, 44, 52, …\n## $ sex      <dbl> 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, …\n## $ cp       <dbl> 3, 0, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2, …\n## $ trestbps <dbl> 145, 140, 130, 120, 130, 140, 140, 1…\n## $ chol     <dbl> 233, 203, 204, 236, 206, 192, 294, 2…\n## $ fbs      <dbl> 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, …\n## $ restecg  <dbl> 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, …\n## $ thalach  <dbl> 150, 155, 172, 178, 132, 148, 153, 1…\n## $ exang    <dbl> 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, …\n## $ oldpeak  <dbl> 2.3, 3.1, 1.4, 0.8, 2.4, 0.4, 1.3, 0…\n## $ slope    <dbl> 0, 0, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, …\n## $ ca       <dbl> 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, …\n## $ thal     <dbl> 1, 3, 2, 2, 3, 1, 2, 3, 3, 2, 2, 2, …\n## $ target   <dbl> 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, …"},{"path":"案例介绍.html","id":"分析思路","chapter":"第 2 部分 案例介绍","heading":"2.3 分析思路","text":"诊断模型：主要是基于研究对象的临床特征，预测当前患有某种疾病的概率，多见于横断面研究;诊断模型：主要是基于研究对象的临床特征，预测当前患有某种疾病的概率，多见于横断面研究;结局类型：分类变量 -> 二分类结局类型：分类变量 -> 二分类数据预处理：\n“整洁”数据：一行是一个样本所有信息、一列是一个variable、中间无乱码、不规范表达\n离群值，异常值、缺失值、协变量的类型等\n数据预处理：“整洁”数据：一行是一个样本所有信息、一列是一个variable、中间无乱码、不规范表达“整洁”数据：一行是一个样本所有信息、一列是一个variable、中间无乱码、不规范表达离群值，异常值、缺失值、协变量的类型等离群值，异常值、缺失值、协变量的类型等模型的选择：Logistic、随机森林、支持向量机模型的选择：Logistic、随机森林、支持向量机其他具体信息，建模中探索其他具体信息，建模中探索","code":""},{"path":"案例介绍.html","id":"算法简介","chapter":"第 2 部分 案例介绍","heading":"2.4 算法简介","text":"","code":""},{"path":"案例介绍.html","id":"logistic","chapter":"第 2 部分 案例介绍","heading":"2.4.1 Logistic","text":"","code":""},{"path":"案例介绍.html","id":"随机森林","chapter":"第 2 部分 案例介绍","heading":"2.4.2 随机森林","text":"","code":""},{"path":"案例介绍.html","id":"支持向量机","chapter":"第 2 部分 案例介绍","heading":"2.4.3 支持向量机","text":"","code":""},{"path":"案例介绍.html","id":"代码预览","chapter":"第 2 部分 案例介绍","heading":"2.5 代码预览","text":"","code":""},{"path":"实操教学-1.html","id":"实操教学-1","chapter":"实操教学","heading":"实操教学","text":"","code":""},{"path":"r-实操.html","id":"r-实操","chapter":"第 3 部分 R 实操","heading":"第 3 部分 R 实操","text":"","code":""},{"path":"r-实操.html","id":"机器学习模型构建","chapter":"第 3 部分 R 实操","heading":"3.1 机器学习模型构建","text":"","code":""},{"path":"r-实操.html","id":"加载需要的r包","chapter":"第 3 部分 R 实操","heading":"3.1.1 加载需要的r包","text":"","code":"\n# rm(list = ls())\nlibrary(tidyverse) # 数据整理\nlibrary(dlookr) # 自动化EDA\nlibrary(plotROC) # 绘制ROC\nlibrary(pROC) # 计算AUC\nlibrary(e1071) # 支持向量机\nlibrary(caret) # 机器学习包\nlibrary(ggplot2)\nlibrary(rms) # 计算校准曲线\\绘制nomo\nlibrary(glmnet) # lasso"},{"path":"r-实操.html","id":"加载数据","chapter":"第 3 部分 R 实操","heading":"3.1.2 加载数据","text":"查看数据情况","code":"\ndata <- read_csv(\"data/CardiovascularDataset.csv\")\n# dlookr 是一个自动输出一份数据诊断报告包，可以自行探索\n# eda_report(data) # 输出诊断报告\n# eda_report(data, target = 1) # 添加按照target的分组信息\n# 查看前10行树\nhead(data,10)## # A tibble: 10 × 14\n##     age   sex    cp trest…¹  chol   fbs restecg thalach\n##   <dbl> <dbl> <dbl>   <dbl> <dbl> <dbl>   <dbl>   <dbl>\n## 1    63     1     3     145   233     1       0     150\n## 2    53     1     0     140   203     1       0     155\n## 3    41     0     1     130   204     0       0     172\n## 4    56     1     1     120   236     0       1     178\n## 5    60     1     0     130   206     0       0     132\n## 6    57     1     0     140   192     0       1     148\n## # … with 4 more rows, 6 more variables: exang <dbl>,\n## #   oldpeak <dbl>, slope <dbl>, ca <dbl>, thal <dbl>,\n## #   target <dbl>, and abbreviated variable name\n## #   ¹​trestbps\n# 查看数据变量属性\nstr(data)## spc_tbl_ [303 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n##  $ age     : num [1:303] 63 53 41 56 60 57 56 44 52 57 ...\n##  $ sex     : num [1:303] 1 1 0 1 1 1 0 1 1 1 ...\n##  $ cp      : num [1:303] 3 0 1 1 0 0 1 1 2 2 ...\n##  $ trestbps: num [1:303] 145 140 130 120 130 140 140 120 172 150 ...\n##  $ chol    : num [1:303] 233 203 204 236 206 192 294 263 199 168 ...\n##  $ fbs     : num [1:303] 1 1 0 0 0 0 0 0 1 0 ...\n##  $ restecg : num [1:303] 0 0 0 1 0 1 0 1 1 1 ...\n##  $ thalach : num [1:303] 150 155 172 178 132 148 153 173 162 174 ...\n##  $ exang   : num [1:303] 0 1 0 0 1 0 0 0 0 0 ...\n##  $ oldpeak : num [1:303] 2.3 3.1 1.4 0.8 2.4 0.4 1.3 0 0.5 1.6 ...\n##  $ slope   : num [1:303] 0 0 2 2 1 1 1 2 2 2 ...\n##  $ ca      : num [1:303] 0 0 0 0 2 0 0 0 0 0 ...\n##  $ thal    : num [1:303] 1 3 2 2 3 1 2 3 3 2 ...\n##  $ target  : num [1:303] 1 0 1 1 0 1 1 1 1 1 ...\n##  - attr(*, \"spec\")=\n##   .. cols(\n##   ..   age = col_double(),\n##   ..   sex = col_double(),\n##   ..   cp = col_double(),\n##   ..   trestbps = col_double(),\n##   ..   chol = col_double(),\n##   ..   fbs = col_double(),\n##   ..   restecg = col_double(),\n##   ..   thalach = col_double(),\n##   ..   exang = col_double(),\n##   ..   oldpeak = col_double(),\n##   ..   slope = col_double(),\n##   ..   ca = col_double(),\n##   ..   thal = col_double(),\n##   ..   target = col_double()\n##   .. )\n##  - attr(*, \"problems\")=<externalptr>"},{"path":"r-实操.html","id":"划分数据集","chapter":"第 3 部分 R 实操","heading":"3.1.3 划分数据集","text":"使用caret包来生成并比较不同的模型与性能。使用sample()函数，将数据集按照8:2随机拆分为训练集（264例）和测试集（61例）为方便后续建模，将target转为factor","code":"\nset.seed(1002)\ntrainset <- sample(nrow(data), 0.8*nrow(data))\ntestset <- data[-trainset,]\ntrainset <- data[trainset, ]\ntrainset$target <- ifelse(trainset$target == 1, \"yes\", \"no\")\ntestset$target <- ifelse(testset$target == 1, \"yes\", \"no\")\ntrainset$target <- as.factor(trainset$target)\ntestset$target <- as.factor(testset$target)\nstr(trainset$target)##  Factor w/ 2 levels \"no\",\"yes\": 1 2 1 2 2 1 1 1 1 1 ...\n# str(testset)"},{"path":"r-实操.html","id":"lasso变量筛选","chapter":"第 3 部分 R 实操","heading":"3.1.4 lasso变量筛选","text":"在统计学习中存在一个重要理论：方差权衡。一般常理认为模型建立得越复杂，分析和预测效果应该越好。而方差权衡恰恰指出了其中的弊端。复杂的模型一般对已知数据（training sample）的拟合（fitting）大过于简单模型，但是复杂模型很容易对数据出现过度拟合（-fitting）。因为所有实际数据都会有各种形式的误差，过度拟合相当于把误差也当做有用的信息进行学习。所以在未知数据（test sample）上的分析和预测效果会大大下降。下图说明了方差权衡的结果。模型复杂度在最低的时候（比如线性回归）预测的偏差比较大，但是方差很小。随着模型复杂度的增大，对已知数据的预测误差会一直下降（因为拟合度增大），而对未知数据却出现拐点，一旦过于复杂，预测方差会变大，模型变得非常不稳定。因此在很多实际生活应用中，线性模型因为其预测方差小，参数估计稳定可靠，仍然起着相当大的作用。正如上面的方差权衡所述，建立线性模型中一个重要的问题就是变量选择（或者叫模型选择），指的是选择建立线性模型所用到的独立变量的选择。在实际问题例如疾病风险控制中，独立变量一般会有200 ~ 300个之多。如果使用所有的变量，很可能会出现模型的过度拟合。所以对变量的选择显得尤为重要。传统的变量选择是采用逐步回归法（stepwise selection），其中又分为向前（forward）和向后（backward）的逐步回归。向前逐步是从0个变量开始逐步加入变量，而向后逐步是从所有变量的集合开始逐次去掉变量。加入或去掉变量一般按照标准的统计信息量来决定。这种传统的变量选择的弊端是模型的方差一般会比较高，而且灵活性较差。近年来回归分析中的一个重大突破是引入了正则化回归（regularized regression）的概念, 而最受关注和广泛应用的正则化回归是1996年由现任斯坦福教授的Robert Tibshirani提出的LASSO回归。LASSO回归最突出的优势在于通过对所有变量系数进行回归惩罚（penalized regression）, 使得相对不重要的独立变量系数变为0，从而排除在建模之外。LASSO方法不同于传统的逐步回归的最大之处是它可以对所有独立变量同时进行处理，而不是逐步处理。这一改进使得建模的稳定性大大增加。除此以外，LASSO还具有计算速度快，模型容易解释等很多优点。而模型发明者Tibshirani教授也因此获得当年的有统计学诺贝尔奖之称的考普斯总统奖（COPSS award）。","code":""},{"path":"r-实操.html","id":"训练集中变量筛选","chapter":"第 3 部分 R 实操","heading":"3.1.4.1 训练集中变量筛选","text":"首先告诉软件，哪些是你的分类变量。分类变量转为因子因子的处理,分类变量处理 onehot encodeing（自由选择）进行拟合，默认为L1也就是Lassoglmnet包在使用cv.glmnet()估计λ值时，默认使用10折交叉验证。在K折交叉验证中，数据被划分成k个相同的子集（折），#每次使用k-1个子集拟合模型，然后使用剩下的那个子集做测试集，最后将k次拟合的结果综合起来（一般取平均数），确定最后的参数。在这个方法中，每个子集只有一次用作测试集。在glmnet包中使用K折交叉验证非常容易，结果包括每次拟合的λ值和响应的MSE。默认设置为α=1。进行交叉验证，选择最优的惩罚系数lambada","code":"\ndata1 <- trainset\n\ndata1[,c(2,3,6,7,9,11:13)] <- lapply(data1[, c(2,3,6,7,9,11:13)], factor)\n\nstr(data1)## tibble [242 × 14] (S3: tbl_df/tbl/data.frame)\n##  $ age     : num [1:242] 57 41 43 37 66 46 60 57 61 44 ...\n##  $ sex     : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 1 2 2 2 2 2 ...\n##  $ cp      : Factor w/ 4 levels \"0\",\"1\",\"2\",\"3\": 1 3 1 3 3 3 1 1 4 1 ...\n##  $ trestbps: num [1:242] 165 130 120 130 146 150 145 110 134 110 ...\n##  $ chol    : num [1:242] 289 214 177 250 278 231 282 335 234 197 ...\n##  $ fbs     : Factor w/ 2 levels \"0\",\"1\": 2 1 1 1 1 1 1 1 1 1 ...\n##  $ restecg : Factor w/ 3 levels \"0\",\"1\",\"2\": 1 1 1 2 1 2 1 2 2 1 ...\n##  $ thalach : num [1:242] 124 168 120 187 152 147 142 143 145 177 ...\n##  $ exang   : Factor w/ 2 levels \"0\",\"1\": 1 1 2 1 1 1 2 2 1 1 ...\n##  $ oldpeak : num [1:242] 1 2 2.5 3.5 0 3.6 2.8 3 2.6 0 ...\n##  $ slope   : Factor w/ 3 levels \"0\",\"1\",\"2\": 2 2 2 1 2 2 2 2 2 3 ...\n##  $ ca      : Factor w/ 5 levels \"0\",\"1\",\"2\",\"3\",..: 4 1 1 1 2 1 3 2 3 2 ...\n##  $ thal    : Factor w/ 4 levels \"0\",\"1\",\"2\",\"3\": 4 3 4 3 3 3 4 4 3 3 ...\n##  $ target  : Factor w/ 2 levels \"no\",\"yes\": 1 2 1 2 2 1 1 1 1 1 ...\n# 为了做lasso把y定义为numeric\ndata1$target <- as.numeric(data1$target)\n# 分类变量转为factor\nx.factors <- model.matrix(data1$target ~ data1$sex + data1$cp+data1$fbs+data1$restecg+data1$exang+data1$slope+data1$ca+data1$thal)[,-1]\n#生成自变量和因变量矩阵\nx=as.matrix(data.frame(x.factors,data1[,c(1,4:5,8,10)]))\n#定义y\ny=data1$target\nfit1 <- glmnet(x,y,family=\"binomial\")\n#解释偏差百分比以及相应的λ值\nprint(fit1)## \n## Call:  glmnet(x = x, y = y, family = \"binomial\") \n## \n##    Df %Dev Lambda\n## 1   0  0.0 0.2410\n## 2   1  2.9 0.2200\n## 3   1  5.3 0.2000\n## 4   3  8.3 0.1830\n## 5   4 11.5 0.1660\n## 6   4 14.5 0.1520\n## 7   5 17.1 0.1380\n## 8   5 19.4 0.1260\n## 9   7 21.5 0.1150\n## 10  7 23.5 0.1050\n## 11  8 25.6 0.0952\n## 12 10 28.0 0.0868\n## 13 11 30.3 0.0791\n## 14 11 32.3 0.0720\n## 15 12 34.2 0.0656\n## 16 12 36.1 0.0598\n## 17 12 37.7 0.0545\n## 18 12 39.2 0.0496\n## 19 12 40.5 0.0452\n## 20 14 41.6 0.0412\n## 21 14 42.8 0.0376\n## 22 14 43.8 0.0342\n## 23 14 44.7 0.0312\n## 24 14 45.6 0.0284\n## 25 14 46.4 0.0259\n## 26 14 47.1 0.0236\n## 27 15 47.7 0.0215\n## 28 16 48.3 0.0196\n## 29 16 48.8 0.0178\n## 30 16 49.3 0.0163\n## 31 16 49.7 0.0148\n## 32 17 50.0 0.0135\n## 33 17 50.4 0.0123\n## 34 18 50.7 0.0112\n## 35 18 51.0 0.0102\n## 36 19 51.2 0.0093\n## 37 19 51.5 0.0085\n## 38 19 51.8 0.0077\n## 39 20 52.0 0.0070\n## 40 20 52.2 0.0064\n## 41 20 52.4 0.0058\n## 42 20 52.5 0.0053\n## 43 20 52.6 0.0049\n## 44 20 52.8 0.0044\n## 45 21 52.9 0.0040\n## 46 21 52.9 0.0037\n## 47 21 53.0 0.0033\n## 48 21 53.1 0.0031\n## 49 21 53.1 0.0028\n## 50 21 53.2 0.0025\n## 51 21 53.2 0.0023\n## 52 21 53.2 0.0021\n## 53 21 53.2 0.0019\n## 54 21 53.3 0.0017\n## 55 21 53.3 0.0016\n## 56 21 53.3 0.0014\n## 57 21 53.3 0.0013\n## 58 21 53.3 0.0012\n## 59 21 53.3 0.0011\n## 60 21 53.3 0.0010\n## 61 21 53.4 0.0009\n## 62 21 53.4 0.0008\n## 63 21 53.4 0.0008\n## 64 21 53.4 0.0007\n## 65 21 53.4 0.0006\n## 66 21 53.4 0.0006\n## 67 21 53.4 0.0005\n## 68 21 53.4 0.0005\n## 69 21 53.4 0.0004\n## 70 21 53.4 0.0004\n## 71 21 53.4 0.0004\n## 72 21 53.4 0.0003\n#解释偏差不再随着λ值的增加而减小，因此而停止\n#画出收缩曲线图\nplot(fit1,label = FALSE)\nplot(fit1,label = TRUE,xvar = \"lambda\")#系数值如何随着λ的变化而变化\nplot(fit1,label = TRUE,xvar = \"dev\")#偏差与系数之间的关系图\n#指定lamda给出相应参数\nlasso.coef <- predict(fit1, type = \"coefficients\",s = 0.040 )\nlasso.coef## 23 x 1 sparse Matrix of class \"dgCMatrix\"\n##                        s1\n## (Intercept)    -0.5051894\n## data1.sex1     -0.4472455\n## data1.cp1       .        \n## data1.cp2       0.6233575\n## data1.cp3       .        \n## data1.fbs1      .        \n## data1.restecg1  0.0148096\n## data1.restecg2  .        \n## data1.exang1   -0.6849315\n## data1.slope1   -0.2724767\n## data1.slope2    0.1970313\n## data1.ca1      -0.9084992\n## data1.ca2      -0.9740841\n## data1.ca3      -0.6171345\n## data1.ca4       .        \n## data1.thal1     .        \n## data1.thal2     0.1821188\n## data1.thal3    -0.7726354\n## age             .        \n## trestbps       -0.0004619\n## chol            .        \n## thalach         0.0129917\n## oldpeak        -0.2474481\nset.seed(317)\ncv.fit <- cv.glmnet(x,y,family=\"binomial\")\n#cv.fit <- cv.glmnet(x,y,family=\"binomial\",type.measure = \"auc\")#AUC和λ的关系\n#cv.fit <- cv.glmnet(x,y,family=\"binomial\")#不要反复运行\nplot(cv.fit)\n#显示一个标准误的系数\ncoef(cv.fit, s = \"lambda.1se\")## 23 x 1 sparse Matrix of class \"dgCMatrix\"\n##                       s1\n## (Intercept)    -0.570950\n## data1.sex1     -0.429630\n## data1.cp1       .       \n## data1.cp2       0.610299\n## data1.cp3       .       \n## data1.fbs1      .       \n## data1.restecg1  0.007149\n## data1.restecg2  .       \n## data1.exang1   -0.678984\n## data1.slope1   -0.261868\n## data1.slope2    0.194103\n## data1.ca1      -0.883563\n## data1.ca2      -0.944469\n## data1.ca3      -0.586744\n## data1.ca4       .       \n## data1.thal1     .       \n## data1.thal2     0.200315\n## data1.thal3    -0.752414\n## age             .       \n## trestbps       -0.000139\n## chol            .       \n## thalach         0.012869\n## oldpeak        -0.245773\n#选择交叉验证误差最小的lambda\ncv.fit$lambda.min## [1] 0.0123\ncv.fit$lambda.1se## [1] 0.04122\ncoef(cv.fit, s = \"lambda.min\")## 23 x 1 sparse Matrix of class \"dgCMatrix\"\n##                       s1\n## (Intercept)     1.718543\n## data1.sex1     -1.058682\n## data1.cp1       0.171712\n## data1.cp2       1.200687\n## data1.cp3       0.727069\n## data1.fbs1      .       \n## data1.restecg1  0.204794\n## data1.restecg2  .       \n## data1.exang1   -0.776428\n## data1.slope1   -0.609627\n## data1.slope2    0.276892\n## data1.ca1      -1.635310\n## data1.ca2      -1.885126\n## data1.ca3      -1.390527\n## data1.ca4       0.131830\n## data1.thal1     .       \n## data1.thal2     .       \n## data1.thal3    -1.084248\n## age             .       \n## trestbps       -0.011442\n## chol           -0.001332\n## thalach         0.015735\n## oldpeak        -0.324021\n#画出收缩系数图，及最小的lambda曲线\nplot(cv.fit$glmnet.fit,xvar=\"lambda\")\nabline(v=log(c(cv.fit$lambda.min,cv.fit$lambda.1se)),lty=2)\n#系数不为0的结果为Lasso筛选后的值\npredict(cv.fit,type='coefficient',s=cv.fit$lambda.min)## 23 x 1 sparse Matrix of class \"dgCMatrix\"\n##                       s1\n## (Intercept)     1.718543\n## data1.sex1     -1.058682\n## data1.cp1       0.171712\n## data1.cp2       1.200687\n## data1.cp3       0.727069\n## data1.fbs1      .       \n## data1.restecg1  0.204794\n## data1.restecg2  .       \n## data1.exang1   -0.776428\n## data1.slope1   -0.609627\n## data1.slope2    0.276892\n## data1.ca1      -1.635310\n## data1.ca2      -1.885126\n## data1.ca3      -1.390527\n## data1.ca4       0.131830\n## data1.thal1     .       \n## data1.thal2     .       \n## data1.thal3    -1.084248\n## age             .       \n## trestbps       -0.011442\n## chol           -0.001332\n## thalach         0.015735\n## oldpeak        -0.324021\npredict(cv.fit,type='coefficient',s=cv.fit$lambda.1se)## 23 x 1 sparse Matrix of class \"dgCMatrix\"\n##                       s1\n## (Intercept)    -0.570950\n## data1.sex1     -0.429630\n## data1.cp1       .       \n## data1.cp2       0.610299\n## data1.cp3       .       \n## data1.fbs1      .       \n## data1.restecg1  0.007149\n## data1.restecg2  .       \n## data1.exang1   -0.678984\n## data1.slope1   -0.261868\n## data1.slope2    0.194103\n## data1.ca1      -0.883563\n## data1.ca2      -0.944469\n## data1.ca3      -0.586744\n## data1.ca4       .       \n## data1.thal1     .       \n## data1.thal2     0.200315\n## data1.thal3    -0.752414\n## age             .       \n## trestbps       -0.000139\n## chol            .       \n## thalach         0.012869\n## oldpeak        -0.245773\npredict(cv.fit,type='coefficient',s=0.1)## 23 x 1 sparse Matrix of class \"dgCMatrix\"\n##                       s1\n## (Intercept)    -1.129256\n## data1.sex1      .       \n## data1.cp1       .       \n## data1.cp2       0.135400\n## data1.cp3       .       \n## data1.fbs1      .       \n## data1.restecg1  .       \n## data1.restecg2  .       \n## data1.exang1   -0.454297\n## data1.slope1    .       \n## data1.slope2    0.052755\n## data1.ca1      -0.036494\n## data1.ca2       .       \n## data1.ca3       .       \n## data1.ca4       .       \n## data1.thal1     .       \n## data1.thal2     0.614504\n## data1.thal3    -0.220414\n## age             .       \n## trestbps        .       \n## chol            .       \n## thalach         0.008586\n## oldpeak        -0.146561"},{"path":"r-实操.html","id":"测试集验证集中-验证","chapter":"第 3 部分 R 实操","heading":"3.1.4.2 测试集\\验证集中 验证","text":"利用lasso在测试集中保存预测值，验证集当中的预测值","code":"\nlibrary(rms)\n#导入验证集\ntest <- testset\nstr(test)## tibble [61 × 14] (S3: tbl_df/tbl/data.frame)\n##  $ age     : num [1:61] 63 56 44 64 58 58 57 61 60 54 ...\n##  $ sex     : num [1:61] 1 0 1 1 0 1 0 0 1 1 ...\n##  $ cp      : num [1:61] 3 1 1 3 2 2 0 0 0 0 ...\n##  $ trestbps: num [1:61] 145 140 120 110 120 132 120 130 130 124 ...\n##  $ chol    : num [1:61] 233 294 263 211 340 224 354 330 253 266 ...\n##  $ fbs     : num [1:61] 1 0 0 0 0 0 0 0 0 0 ...\n##  $ restecg : num [1:61] 0 0 1 0 1 0 1 0 1 0 ...\n##  $ thalach : num [1:61] 150 153 173 144 172 173 163 169 144 109 ...\n##  $ exang   : num [1:61] 0 0 0 1 0 0 1 0 1 1 ...\n##  $ oldpeak : num [1:61] 2.3 1.3 0 1.8 0 3.2 0.6 0 1.4 2.2 ...\n##  $ slope   : num [1:61] 0 1 2 1 2 2 2 2 2 1 ...\n##  $ ca      : num [1:61] 0 0 0 0 0 2 0 0 1 1 ...\n##  $ thal    : num [1:61] 1 2 3 2 2 3 2 2 3 3 ...\n##  $ target  : Factor w/ 2 levels \"no\",\"yes\": 2 2 2 2 2 1 2 1 1 1 ...\ntest$target <- as.numeric(test$target)\n#制作x矩阵\ntest[,c(2,3,6,7,9,11:13)] <- lapply(test[, c(2,3,6,7,9,11:13)], factor)\n\nx.factors_test <- model.matrix(test$target ~ test$sex + test$cp+test$fbs+test$restecg+test$exang+test$slope+test$ca+test$thal)[,-1]\n\nnewx=as.matrix(data.frame(x.factors_test,test[,c(1,4:5,8,10)]))\ntest.y <- predict(cv.fit, newx = newx, type = \"response\", s=cv.fit$lambda.1se)\nlibrary(rms)\n#在R当中做calibration plot\ntest <- data.frame(test,test.y)\n# write.csv(test,file=\"test0.csv\")\n# str(test)\n##########val.prob#####\nval.prob(test$s1,test$target)##        Dxy    C (ROC)         R2          D   D:Chi-sq \n##  9.143e-01  9.571e-01  6.671e-01  6.701e-01  4.187e+01 \n##        D:p          U   U:Chi-sq        U:p          Q \n##         NA -3.602e-01 -1.997e+01  1.000e+00  1.030e+00 \n##      Brier  Intercept      Slope       Emax        E90 \n##  1.134e+00 -6.258e-02  2.432e+00  1.180e+00  1.168e+00 \n##       Eavg        S:z        S:p \n##  1.016e+00 -6.885e+00  5.791e-12"},{"path":"r-实操.html","id":"训练集建立模型","chapter":"第 3 部分 R 实操","heading":"3.1.5 训练集建立模型","text":"训练Logistic训练随机森林训练SVM","code":"\nfitControl = trainControl(method = \"none\", classProbs = TRUE)\n\nset.seed(10101) # 设置种子数，复现结果\nLR_model <- train(target~. ,\n                  data = trainset,\n                  method = \"glm\",\n                  trControl = fitControl,\n                  metric = \"ROC\")\nset.seed(10101) # 设置种子数，复现结果\nRF_model <- train(target~. ,\n                  data = trainset,\n                  method = \"parRF\",\n                  trControl = fitControl,\n                  metric = \"ROC\")\nset.seed(10101) # 设置种子数，复现结果\nSVM_model <- train(target~. ,\n                  data = trainset,\n                  method = \"svmRadial\",\n                  trControl = fitControl,\n                  metric = \"ROC\")"},{"path":"r-实操.html","id":"测试集评价模型","chapter":"第 3 部分 R 实操","heading":"3.1.6 测试集评价模型","text":"获得模型测试集风险概率使用plotROC包和ggplot2绘制ROC曲线pROC包的roc()和auc()函数，计算AUC","code":"\nLR_pro <- predict (LR_model, newdata =testset, type= \"prob\") \nRF_pro <- predict (RF_model, newdata =testset, type= \"prob\") \nSVM_pro <-  predict (SVM_model, newdata =testset, type= \"prob\")\n\ntestset$LR <- LR_pro$yes\ntestset$RF <- RF_pro$yes\ntestset$SVM <- SVM_pro$yes\nROC <- melt_roc(testset, \"target\", c(\"LR\", \"RF\", \"SVM\"))\nROC_plot <- ggplot(ROC, aes(d = D.target, m = M, color = name)) +\n    geom_roc(n.cuts = 0) +\n    labs(title = \"三种模型测试集ROC曲线\") + \n    theme(plot.title = element_text(hjust = 0.5))+\n    geom_abline()\n# theme(text = element_text(size = 50)) 设置所有字体大小\nROC_plot\nroc_LR <- roc(testset$target, testset$LR)\nauc_LR <- auc(roc_LR)\nauc_LR   # Area under the curve: 0.956## Area under the curve: 0.956\nroc_RF <- roc(testset$target, testset$RF)\nauc_RF <- auc(roc_RF)\nauc_RF   # Area under the curve: 0.935## Area under the curve: 0.935\nroc_SVM <- roc(testset$target, testset$SVM)\nauc_SVM <- auc(roc_SVM)\nauc_SVM  # Area under the curve: 0.969## Area under the curve: 0.969"},{"path":"r-实操.html","id":"logistic-dca曲线","chapter":"第 3 部分 R 实操","heading":"3.1.7 Logistic DCA曲线","text":"DCA曲线横坐标是判断恶性/良性的风险阈值（0~1），纵坐标为不同阈值对应的临床净获益（net benifit）。主要比较了根据四种模型划分恶性/良性患者（针对性干预），相比于把所有患者都看作恶性实施干预（ALL曲线）和所有患者都不干预（None曲线），是否有临床净获益。006年首次介绍了DCA曲线，并提供了使用R语言绘制DCA曲线的dca()函代码下载链接：https://www.mskcc.org/departments/epidemiology-biostatistics/biostatistics/decision-curve-analysis能够看到，当风险阈值范围在0~1 时，模型的临床净获益均高于ALL曲线和None曲线，能够取得临床净获益的阈值范围还是比较大的，但应该注意的是，随着阈值增大，模型的临床净获益也在减小。","code":"\ntestset$target <- ifelse(testset$target == \"yes\", 1, 0)\n# write_csv(testset, file = \"data/testset.csv\")\nsource(\"dca/dca.r\")\ntestset1 <- read.csv(\"data/testset.csv\")\nDCA <- dca(data = testset1, outcome = \"target\",\n           predictors = c(\"LR\"))"},{"path":"r-实操.html","id":"logistic的nomogram绘制","chapter":"第 3 部分 R 实操","heading":"3.1.8 Logistic的Nomogram绘制","text":"另外一种","code":"\n# 解决\"variable 变量名 does not have limits defined by datadist\"\ndd <- datadist(testset)\noptions(datadist=\"dd\")\n\n# 设置变量标签\ntestset$sex <- factor(testset$sex,levels=c(0,1),labels=c(\"Female\",\"Male\"))\n# 构建LR模型\nf1 <- lrm(target~ age+sex+chol+oldpeak, data= testset, x = T, y = T)\n# 绘制Nomogram\nnom <- nomogram(f1,\n                fun=function(x)1/(1+exp(-x)),\n                #也可fun=plogis,fun.at概率坐标范围\n                fun.at=c(.001,.01,.05,seq(.1,.9,by=.1),.95,.99,.999),\n                funlabel=\"Risk of target\",\n                conf.int=F,\n                abbrev=F,\n                minlength=1,\n                #lp线性预测值\n                lp=F)\nplot(nom)\nlibrary(regplot)\nregplot(f1)## [1] \"note: points tables not constructed unless points=TRUE \""},{"path":"python-安装与入门.html","id":"python-安装与入门","chapter":"第 4 部分 Python 安装与入门","heading":"第 4 部分 Python 安装与入门","text":"","code":""},{"path":"python-安装与入门.html","id":"anaconda-的安装","chapter":"第 4 部分 Python 安装与入门","heading":"4.1 Anaconda 的安装","text":"","code":""},{"path":"python-安装与入门.html","id":"anaconda简介","chapter":"第 4 部分 Python 安装与入门","heading":"4.1.1 Anaconda简介","text":"Anaconda，是一个开源的Python发行版本，其包含了conda、Python以及一大堆安装好的工具包及依赖项，比如numpy、pandas、matplotlib等。conda是一个开源的包、环境管理器，可以用于在同一个机器上安装不同版本的软件包及其依赖，并能够在不同的环境之间切换。不同的Python项目常常会对应不同的Python版本和依赖包版本，使用conda就可以方便的对不同的环境进行管理。Anaconda还附带了数据分析常用的Jupyter Notebook，之前被称为 IPython notebook，是一个交互式笔记本。Jupyter Notebook 的本质是一个 Web应用程序，可以将代码、图像和文档全部组合到一个web文档中，便于创建和共享程序文档，支持实时代码，数学方程，可视化和markdown，在数据清理和转换，数据分析，统计建模，机器学习等方面应用广泛。","code":""},{"path":"python-安装与入门.html","id":"anaconda-下载","chapter":"第 4 部分 Python 安装与入门","heading":"4.1.2 Anaconda 下载","text":"官网：https://www.anaconda.com/官网：https://www.anaconda.com/百度云：\n链接：https://pan.baidu.com/s/1lr5ks5FiTgCrS-jrXdNZQQ?pwd=ab5q\n提取码：ab5q百度云：链接：https://pan.baidu.com/s/1lr5ks5FiTgCrS-jrXdNZQQ?pwd=ab5q提取码：ab5q","code":""},{"path":"python-安装与入门.html","id":"安装步骤","chapter":"第 4 部分 Python 安装与入门","heading":"4.1.3 安装步骤","text":"双击安装包进行安装，点击下一步。选择安装位置，一定要记住。出现下面的界面，选择安装路径，尽量不要装入系统盘，系统盘的空间资源很宝贵。建议安装到其他盘，注意安装路径不要包含汉字并且尽量不要包含空格。选择后安装路径之后，点击 next。比如，我安装位置为：G:\\develop\\anaconda这一步是选择是否勾选环境变量，这里暂时先不勾选，后面再配置好了。之后点击install进行安装即可。安装进行中，等待安装完成。 一会儿之后就会安装完成，根据如下提示进行勾选和不勾选即可，点击finish，表示安装完成。 安装完成后手动添加环境变量第一步：此电脑>右键>属性>高级系统设置第二步：点击环境变量第三步：选择系统变量中的path>编辑第四步：新建环境变量第五步：输入本地的anaconda的相关目录，注意这个目录是你自己的安装目录。下面是我的anaconda相关目录：G:\\develop\\anacondaG:\\develop\\anaconda\\Library\\mingw-w64\\binG:\\develop\\anaconda\\Library\\usr\\binG:\\develop\\anaconda\\Library\\binG:\\develop\\anaconda\\Scripts要把以上目录修改成自己的anaconda安装目录。比如你的anaconda安装在E盘下，那么就写成E:\\anaconda，E:\\anaconda\\Library\\mingw-w64\\bin 等等。第六步：依次点击确定关闭所有的windows窗口，重启cmdwin+R输入：cmd第七步：输入conda --version验证（注意空格，注意两个横线）如果如下图所示，就代表配置成功了。conda后面的数字可以不一样，这个是conda的版本信息","code":""},{"path":"python-安装与入门.html","id":"conda基本命令","chapter":"第 4 部分 Python 安装与入门","heading":"4.1.4 conda基本命令","text":"添加镜像基本命令","code":"# 为了装包速度快点，添加国内镜像\n\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/\nconda config --set show_channel_urls yesconda list    #查看当前环境所安装的包\nconda install numpy # 安装包\nconda install python=2.7    #安装指定版本包或软件\nconda uninstall numpy  # 卸载包\n\npip list    #查看当前环境所安装的包\npip install numpy # 安装包\n\n# 可以在使用pip的时候加参数-i https://pypi.tuna.tsinghua.edu.cn/simple \n# 例如：pip install -i https://pypi.tuna.tsinghua.edu.cn/simple gevent，这样就会从清华这边的镜像去安装gevent库。"},{"path":"python-安装与入门.html","id":"打开jupyter-notebook","chapter":"第 4 部分 Python 安装与入门","heading":"4.1.5 打开jupyter notebook","text":"将带有.ipynb 文件夹放到桌面打开 anaconda prompt输入： cd desktop 按回车键接着输入：jupyter notebook 按回车键稍等一会，打开自带浏览器，找到python这个文件，打开点python-example.ipynb文件就可以了","code":""},{"path":"python-安装与入门.html","id":"python-入门","chapter":"第 4 部分 Python 安装与入门","heading":"4.2 python 入门","text":"推荐教程：https://www.cainiaojc.com/python/python-tutorial.html简单介绍：文档链接: https://www.mubucm.com/doc/5y3mswgOYWg文档链接: https://www.mubucm.com/doc/3U7gD8xHiWg","code":""},{"path":"r安装与入门.html","id":"r安装与入门","chapter":"第 5 部分 R安装与入门","heading":"第 5 部分 R安装与入门","text":"","code":""},{"path":"r安装与入门.html","id":"r与rstudio的安装","chapter":"第 5 部分 R安装与入门","heading":"5.1 r与Rstudio的安装","text":"","code":""},{"path":"r安装与入门.html","id":"r简介","chapter":"第 5 部分 R安装与入门","heading":"5.1.1 R简介","text":"R（语言）是一套完整的数据处理、计算和制图软件系统。其功能包括：数据存储和处理系统，数组运算工具，完整连贯的统计分析工具，优秀的统计制图功能。R软件具有简便而强大的编程语言工具。官方的 R 软件环境是GNU 软件包中的开源自由软件环境，可在GNU 通用公共许可证下获得。它主要用C、Fortran和 R 本身（部分自托管）编写，为各种操作系统提供了预编译的可执行文件。R有一个命令行界面。还提供多个第三方图形用户界面，例如集成开发环境RStudio。 RStudio是一个功能强大、节省成本的反删除和数据恢复软件，且具有强大、简洁、易操作的编程软件。RStudio是辅助R进行编辑的语言工具，而它自身不附带R程序。所以必须先安装R软件，再安装RStudio软件，而编程操作都在RStudio中完成。","code":""},{"path":"r安装与入门.html","id":"r下载","chapter":"第 5 部分 R安装与入门","heading":"5.1.2 R下载","text":"官网：\nR官网：https://www.r-project.org/\nRstudio官网：https://www.rstudio.com/products/rstudio/官网：R官网：https://www.r-project.org/Rstudio官网：https://www.rstudio.com/products/rstudio/百度云：\n链接：https://pan.baidu.com/s/1lr5ks5FiTgCrS-jrXdNZQQ?pwd=ab5q\n提取码：ab5q百度云：链接：https://pan.baidu.com/s/1lr5ks5FiTgCrS-jrXdNZQQ?pwd=ab5q提取码：ab5q","code":""},{"path":"r安装与入门.html","id":"r的安装","chapter":"第 5 部分 R安装与入门","heading":"5.1.3 R的安装","text":"选择【R-4.2.1】，右击选择【以管理员身份运行】,选择【中文（简体）】打开后会显示安装向导，点击【下一步】开始安装。选择安装位置，默认的是C盘，安装路径必须是非中文路径。建议选择其他位置以下全部为默认，点击【下一步】，直到完成安装。","code":""},{"path":"r安装与入门.html","id":"安装rstudio","chapter":"第 5 部分 R安装与入门","heading":"5.1.4 安装Rstudio","text":"双击安装程序双击安装程序欢迎界面，点击【下一步】欢迎界面，点击【下一步】选择安装位置：选择与R-4.2.1一样的安装路径。一路默认安装，直至完成双击Rstudio图标打开Rstudio 初始界面","code":""},{"path":"r安装与入门.html","id":"r入门","chapter":"第 5 部分 R安装与入门","heading":"R入门","text":"推荐教程：李东风 R语言教程","code":""},{"path":"r入门-1.html","id":"r入门-1","chapter":"第 6 部分 R入门","heading":"第 6 部分 R入门","text":"","code":""},{"path":"r入门-1.html","id":"基础拾遗","chapter":"第 6 部分 R入门","heading":"6.1 基础拾遗","text":"","code":""},{"path":"r入门-1.html","id":"rstudio-设置","chapter":"第 6 部分 R入门","heading":"6.1.1 Rstudio 设置","text":"初识RstudioRstudio 默认由四个窗口组成，分别为：代码编辑窗口，环境变量窗口，控制台，以及绘图帮助窗口。窗口可以通过拖动分割柱移动。个性化Tools -> Global Options -> Appearance -> 设定喜欢的编辑界面packages 下载镜像设置Tools -> Global Options -> Packages -> primary CRAN repository ->changes(选择距离你最近的镜像)注意！ R 包安装成功后，要及时注释安装语句，避免重复安装。注释： R 语言中，在代码前面加 “#” 号表示该行后面的内容为解释性语句，默认不运行。快捷键:Ctrl+shift+C","code":"# 下载 R 包：\ninstall.packages(\"tidyverse\")  注意打上英文的引号哦！ Ctrl+enter 运行！！\n# 加载 R 包：\nlibrary(tidyverse) # 注意并不需要引号哦！\n# install.packages(\"tidyverse\")"},{"path":"r入门-1.html","id":"创建一个-r-脚本","chapter":"第 6 部分 R入门","heading":"6.1.2 创建一个 R 脚本","text":"快捷键 Ctrl+shift+N, 或点击右上角绿色加号 -> R Script。R 脚本（后缀名.R）是我们在上面编写程序以实现特定功能的文档。写脚本的注意事项:脚本不应太长，一个脚本实现一个任务；养成注释的好习惯 (ctrl+shift+c)；保存脚本：保存脚本：打开脚本：\n如果出现中文为乱码，则点击 File -> Reopen Encoding -> 选择其他中文编码。常见的中文编码类型有； UTF-8， GBK 等。打开脚本：如果出现中文为乱码，则点击 File -> Reopen Encoding -> 选择其他中文编码。常见的中文编码类型有； UTF-8， GBK 等。","code":""},{"path":"r入门-1.html","id":"演示","chapter":"第 6 部分 R入门","heading":"6.1.3 演示：","text":"设定工作路径:加载 R 包：读取数据:这个语句里面， read.csv 表示在当前工作路径下，读取一个名为 data.csv 的文档； header=T 表示表头为真， T 为 TRUE 的缩写。然后，通过赋值符号”<-“将读取的数据存储在变量 mydata 这里查看数据:","code":"\n# set working directory\nsetwd(\"D:\\\\数据\") # 注意：斜杠与反斜杠，双反斜杠的不同\nlibrary(tidyverse)\nmydata <- read.csv(\"data/CardiovascularDataset.csv\",header = T) \n# header=True 表示有表头\ncolnames(mydata) #col 为 colnumn 的前三个字母\n# 查看数据结构\nstr(mydata)# str 为 structure 的前三个字母## 'data.frame':    303 obs. of  14 variables:\n##  $ age     : int  63 53 41 56 60 57 56 44 52 57 ...\n##  $ sex     : int  1 1 0 1 1 1 0 1 1 1 ...\n##  $ cp      : int  3 0 1 1 0 0 1 1 2 2 ...\n##  $ trestbps: int  145 140 130 120 130 140 140 120 172 150 ...\n##  $ chol    : int  233 203 204 236 206 192 294 263 199 168 ...\n##  $ fbs     : int  1 1 0 0 0 0 0 0 1 0 ...\n##  $ restecg : int  0 0 0 1 0 1 0 1 1 1 ...\n##  $ thalach : int  150 155 172 178 132 148 153 173 162 174 ...\n##  $ exang   : int  0 1 0 0 1 0 0 0 0 0 ...\n##  $ oldpeak : num  2.3 3.1 1.4 0.8 2.4 0.4 1.3 0 0.5 1.6 ...\n##  $ slope   : int  0 0 2 2 1 1 1 2 2 2 ...\n##  $ ca      : int  0 0 0 0 2 0 0 0 0 0 ...\n##  $ thal    : int  1 3 2 2 3 1 2 3 3 2 ...\n##  $ target  : int  1 0 1 1 0 1 1 1 1 1 ...\n# 查看分类变量的取值（唯一值）\nunique(mydata$sex) # 美元符号 $ 表示索引，按变量名索引。## [1] 1 0\nunique(mydata$target)"},{"path":"r入门-1.html","id":"一些快捷键","chapter":"第 6 部分 R入门","heading":"6.1.4 一些快捷键","text":"窗口可以通过拖动分割柱移动，也可以使用快捷键控制。比如：Ctrl+shift+1(2\\3\\4)窗口可以通过拖动分割柱移动，也可以使用快捷键控制。比如：Ctrl+shift+1(2\\3\\4)创建一个R脚本 ——Ctrl+shift+N创建一个R脚本 ——Ctrl+shift+N快速注释——Ctrl+shift+C快速注释——Ctrl+shift+C善于利用小标题实现功能分区（ctrl+shift+r）善于利用小标题实现功能分区（ctrl+shift+r）ctrl+alt+r ——快速插入代码框ctrl+alt+r ——快速插入代码框注释（Ctrl+shift+c）； # ；注释（Ctrl+shift+c）； # ；赋值（Alt+-）： =, <- ;赋值（Alt+-）： =, <- ;函数的标志： ();函数的标志： ();变量索引： $;变量索引： $;管道操作符： %>%， |>：读作 “然后” ;管道操作符： %>%， |>：读作 “然后” ;比较或判断： >, < , >=, <=, ==, != ；比较或判断： >, < , >=, <=, ==, != ；逻辑运算： &(与), |(或), !(非) ;逻辑运算： &(与), |(或), !(非) ;算数运算： +， -， *， /, ^, %%(取余), %/%(整除)。算数运算： +， -， *， /, ^, %%(取余), %/%(整除)。","code":""},{"path":"r入门-1.html","id":"数据基本操作","chapter":"第 6 部分 R入门","heading":"6.2 数据基本操作","text":"","code":""},{"path":"r入门-1.html","id":"读取数据","chapter":"第 6 部分 R入门","heading":"6.2.1 读取数据","text":"","code":"\nmydata <- read_csv(\"data/CardiovascularDataset.csv\") # 读取数据\n# knitr::kable(mydata, align = \"c\")\n\ncolnames(mydata) # 查看表头\nstr(mydata) # 查看数据结构\nunique(mydata$cause) # 查看分类变量的取值（唯一值）\n# 其他查看数据的函数\n# summary(mydata)\n# head(mydata)\n# tail(mydata)"},{"path":"r入门-1.html","id":"选择数据","chapter":"第 6 部分 R入门","heading":"6.2.2 选择数据","text":"这里面出现了管道操作符号” |> “, 这个符号读作：然后。所以这个语句的意思是：首先，选中 mydata，然后，选择 cause 为”HIV/AIDS” 的行，然后，选择年份为 2019 年的行，最后，将选择好的数据赋值给 mydata2。特别注意： = 是赋值符， == 为判断符。","code":"\nmydata2 <- mydata |> # 管道操作符： %>% 或者 |> ，读作然后\n    filter(sex== 1) |>\n    filter(target==1)\nmydata2##    age sex cp trestbps chol fbs restecg thalach exang\n## 1   63   1  3      145  233   1       0     150     0\n## 2   56   1  1      120  236   0       1     178     0\n## 3   57   1  0      140  192   0       1     148     0\n## 4   44   1  1      120  263   0       1     173     0\n## 5   52   1  2      172  199   1       1     162     0\n## 6   57   1  2      150  168   0       1     174     0\n## 7   54   1  0      140  239   0       1     160     0\n## 8   49   1  1      130  266   0       1     171     0\n## 9   64   1  3      110  211   0       0     144     1\n## 10  37   1  2      130  250   0       1     187     0\n## 11  47   1  0      112  204   0       1     143     0\n## 12  42   1  1      120  295   0       1     162     0\n## 13  41   1  1      110  235   0       1     153     0\n## 14  62   1  1      128  208   1       0     140     0\n## 15  57   1  0      110  201   0       1     126     1\n## 16  64   1  0      128  263   0       1     105     1\n## 17  43   1  0      115  303   0       1     181     0\n## 18  70   1  1      156  245   0       0     143     0\n## 19  48   1  2      124  255   1       1     175     0\n## 20  57   1  0      132  207   0       1     168     1\n## 21  52   1  2      138  223   0       1     169     0\n## 22  53   1  0      142  226   0       0     111     1\n## 23  52   1  0      108  233   1       1     147     0\n## 24  43   1  2      130  315   0       1     162     0\n## 25  53   1  2      130  246   1       0     173     0\n## 26  42   1  3      148  244   0       0     178     0\n## 27  59   1  3      178  270   0       0     145     0\n## 28  42   1  2      120  240   1       1     194     0\n## 29  50   1  2      129  196   0       1     163     0\n## 30  69   1  3      160  234   1       0     131     0\n## 31  57   1  2      150  126   1       1     173     0\n## 32  43   1  0      110  211   0       1     161     0\n## 33  55   1  1      130  262   0       1     155     0\n## 34  41   1  2      130  214   0       0     168     0\n## 35  56   1  3      120  193   0       0     162     0\n## 36  59   1  0      138  271   0       0     182     0\n## 37  44   1  2      120  226   0       1     169     0\n## 38  42   1  2      130  180   0       1     150     0\n## 39  66   1  0      160  228   0       0     138     0\n## 40  64   1  3      170  227   0       0     155     0\n## 41  47   1  2      130  253   0       1     179     0\n## 42  35   1  1      122  192   0       1     174     0\n## 43  58   1  1      125  220   0       1     144     0\n## 44  56   1  1      130  221   0       0     163     0\n## 45  56   1  1      120  240   0       1     169     0\n## 46  41   1  1      120  157   0       1     182     0\n## 47  38   1  2      138  175   0       1     173     0\n## 48  38   1  2      138  175   0       1     173     0\n## 49  43   1  0      150  247   0       1     171     0\n## 50  59   1  0      135  234   0       1     161     0\n## 51  44   1  2      130  233   0       1     179     1\n## 52  42   1  0      140  226   0       1     178     0\n## 53  61   1  2      150  243   1       1     137     1\n## 54  40   1  3      140  199   0       1     178     1\n## 55  59   1  2      150  212   1       1     157     0\n## 56  51   1  2      110  175   0       1     123     0\n## 57  53   1  2      130  197   1       0     152     0\n## 58  65   1  0      120  177   0       1     140     0\n## 59  44   1  1      130  219   0       0     188     0\n## 60  54   1  2      125  273   0       0     152     0\n## 61  51   1  3      125  213   0       0     125     1\n## 62  54   1  2      150  232   0       0     165     0\n## 63  48   1  1      130  245   0       0     180     0\n## 64  45   1  0      104  208   0       0     148     1\n## 65  39   1  2      140  321   0       0     182     0\n## 66  52   1  1      120  325   0       1     172     0\n## 67  44   1  2      140  235   0       0     180     0\n## 68  47   1  2      138  257   0       0     156     0\n## 69  66   1  0      120  302   0       0     151     0\n## 70  62   1  2      130  231   0       1     146     0\n## 71  52   1  1      134  201   0       1     158     0\n## 72  48   1  0      122  222   0       0     186     0\n## 73  45   1  0      115  260   0       0     185     0\n## 74  34   1  3      118  182   0       0     174     0\n## 75  54   1  1      108  309   0       1     156     0\n## 76  52   1  3      118  186   0       0     190     0\n## 77  41   1  1      135  203   0       1     132     0\n## 78  58   1  2      140  211   1       0     165     0\n## 79  51   1  2      100  222   0       1     143     1\n## 80  44   1  1      120  220   0       1     170     0\n## 81  54   1  2      120  258   0       0     147     0\n## 82  51   1  2       94  227   0       1     154     1\n## 83  29   1  1      130  204   0       0     202     0\n## 84  51   1  0      140  261   0       0     186     1\n## 85  51   1  2      125  245   1       0     166     0\n## 86  59   1  1      140  221   0       1     164     1\n## 87  52   1  1      128  205   1       1     184     0\n## 88  58   1  2      105  240   0       0     154     1\n## 89  41   1  2      112  250   0       1     179     0\n## 90  45   1  1      128  308   0       0     170     0\n## 91  52   1  3      152  298   1       1     178     0\n## 92  68   1  2      118  277   0       1     151     0\n## 93  46   1  1      101  197   1       1     156     0\n##    oldpeak slope ca thal target\n## 1      2.3     0  0    1      1\n## 2      0.8     2  0    2      1\n## 3      0.4     1  0    1      1\n## 4      0.0     2  0    3      1\n## 5      0.5     2  0    3      1\n## 6      1.6     2  0    2      1\n## 7      1.2     2  0    2      1\n## 8      0.6     2  0    2      1\n## 9      1.8     1  0    2      1\n## 10     3.5     0  0    2      1\n## 11     0.1     2  0    2      1\n## 12     0.0     2  0    2      1\n## 13     0.0     2  0    2      1\n## 14     0.0     2  0    2      1\n## 15     1.5     1  0    1      1\n## 16     0.2     1  1    3      1\n## 17     1.2     1  0    2      1\n## 18     0.0     2  0    2      1\n## 19     0.0     2  2    2      1\n## 20     0.0     2  0    3      1\n## 21     0.0     2  4    2      1\n## 22     0.0     2  0    3      1\n## 23     0.1     2  3    3      1\n## 24     1.9     2  1    2      1\n## 25     0.0     2  3    2      1\n## 26     0.8     2  2    2      1\n## 27     4.2     0  0    3      1\n## 28     0.8     0  0    3      1\n## 29     0.0     2  0    2      1\n## 30     0.1     1  1    2      1\n## 31     0.2     2  1    3      1\n## 32     0.0     2  0    3      1\n## 33     0.0     2  0    2      1\n## 34     2.0     1  0    2      1\n## 35     1.9     1  0    3      1\n## 36     0.0     2  0    2      1\n## 37     0.0     2  0    2      1\n## 38     0.0     2  0    2      1\n## 39     2.3     2  0    1      1\n## 40     0.6     1  0    3      1\n## 41     0.0     2  0    2      1\n## 42     0.0     2  0    2      1\n## 43     0.4     1  4    3      1\n## 44     0.0     2  0    3      1\n## 45     0.0     0  0    2      1\n## 46     0.0     2  0    2      1\n## 47     0.0     2  4    2      1\n## 48     0.0     2  4    2      1\n## 49     1.5     2  0    2      1\n## 50     0.5     1  0    3      1\n## 51     0.4     2  0    2      1\n## 52     0.0     2  0    2      1\n## 53     1.0     1  0    2      1\n## 54     1.4     2  0    3      1\n## 55     1.6     2  0    2      1\n## 56     0.6     2  0    2      1\n## 57     1.2     0  0    2      1\n## 58     0.4     2  0    3      1\n## 59     0.0     2  0    2      1\n## 60     0.5     0  1    2      1\n## 61     1.4     2  1    2      1\n## 62     1.6     2  0    3      1\n## 63     0.2     1  0    2      1\n## 64     3.0     1  0    2      1\n## 65     0.0     2  0    2      1\n## 66     0.2     2  0    2      1\n## 67     0.0     2  0    2      1\n## 68     0.0     2  0    2      1\n## 69     0.4     1  0    2      1\n## 70     1.8     1  3    3      1\n## 71     0.8     2  1    2      1\n## 72     0.0     2  0    2      1\n## 73     0.0     2  0    2      1\n## 74     0.0     2  0    2      1\n## 75     0.0     2  0    3      1\n## 76     0.0     1  0    1      1\n## 77     0.0     1  0    1      1\n## 78     0.0     2  0    2      1\n## 79     1.2     1  0    2      1\n## 80     0.0     2  0    2      1\n## 81     0.4     1  0    3      1\n## 82     0.0     2  1    3      1\n## 83     0.0     2  0    2      1\n## 84     0.0     2  0    2      1\n## 85     2.4     1  0    2      1\n## 86     0.0     2  0    2      1\n## 87     0.0     2  0    2      1\n## 88     0.6     1  0    3      1\n## 89     0.0     2  0    2      1\n## 90     0.0     2  0    2      1\n## 91     1.2     1  0    3      1\n## 92     1.0     2  1    3      1\n## 93     0.0     2  0    3      1"},{"path":"r入门-1.html","id":"保存数据","chapter":"第 6 部分 R入门","heading":"6.2.3 保存数据","text":"","code":"\nwrite.csv(mydata2, # 将 mydata2 这个数据\n\"data/sex1_target.csv\") # 保存为 HIV.csv 文件\n\nsave(mydata2, file = \"mydata2.Rdata\")\nload(\"mydata2.Rdata\")"},{"path":"r入门-1.html","id":"数据类型与数据结构","chapter":"第 6 部分 R入门","heading":"6.3 数据类型与数据结构","text":"","code":""},{"path":"r入门-1.html","id":"常见的数据类型","chapter":"第 6 部分 R入门","heading":"6.3.1 常见的数据类型","text":"R 语言常见数据类型有：数值类型（numeric），字符串（character），逻辑（logical），其他： POSIXct,POSIXt 等。数值类型： 1， 2， 3， 4.5,3.8;字符串类型：“字符”， “123”， “ASIR”， “HIV”逻辑： TRUE， FALSE, T, F;","code":"\nclass(1)## [1] \"numeric\"\ntypeof(4.5)## [1] \"double\"\nclass(\"123\")## [1] \"character\"\ntypeof(\"ASIR\")## [1] \"character\"\nclass(T)## [1] \"logical\"\ntypeof(FALSE)## [1] \"logical\""},{"path":"r入门-1.html","id":"特殊数据类型-naninf-na-null","chapter":"第 6 部分 R入门","heading":"6.3.2 特殊数据类型： NaN,Inf， NA， NULL","text":"NaN:number, 计算出错时候出现，比如 0/0,Inf/InfNaN:number, 计算出错时候出现，比如 0/0,Inf/InfInf : 无穷Inf : 无穷NA：availabel，缺失值。 NA 值具有传染性，任何数值与之发生关系均会变为 NANA：availabel，缺失值。 NA 值具有传染性，任何数值与之发生关系均会变为 NANULL：空值。空值与 NA 的区别：比如一个教室稀稀拉拉坐了十几个学生，那么没有学生的位置可以视为缺失，而空值表示连座位也没有。NULL：空值。空值与 NA 的区别：比如一个教室稀稀拉拉坐了十几个学生，那么没有学生的位置可以视为缺失，而空值表示连座位也没有。","code":""},{"path":"r入门-1.html","id":"数据类型的转换","chapter":"第 6 部分 R入门","heading":"6.3.3 数据类型的转换","text":"numeric 与 logical 可以转化为 character，而 character 转化为 numeric 或者 logical 有可能出错，产生 NA 值。logical 可以转化为数值 0/1, 而在进行逻辑判断的时候， 0/1 也会被认为是 F/T","code":"\na <- as.character(1990)\nclass(a)## [1] \"character\"\nb <- as.numeric(\"1990\")\nclass(b)## [1] \"numeric\"\nc <- as.numeric(\"ABC\")\n## Warning: 强制改变过程中产生了NA\nc## [1] NA\nas.numeric(TRUE)## [1] 1\nas.logical(1)## [1] TRUE"},{"path":"r入门-1.html","id":"数据结构","chapter":"第 6 部分 R入门","heading":"6.3.4 数据结构","text":"标量单个元素组成的数据结构，比如””,123,TRUE 等。### 向量多个标量组成的一维的数据结构，比如 Vector。矩阵 (matrix)，数据框 (data.frame)， tipple矩阵 (matrix)，数据框 (data.frame)， tipple列表 (list) 与数组 (array)列表 (list) 与数组 (array)","code":"\n# 生成向量\na <- c(1990:2019)\na##  [1] 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999\n## [11] 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009\n## [21] 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019\nb <- c(1,2,3,4,5,6)\nb## [1] 1 2 3 4 5 6\nc <- rep(\"A\",3) #repeat 前三个字母\nc## [1] \"A\" \"A\" \"A\"\nd <- seq(from=1,to=10,by=2) #sequence 前三个字母\nd## [1] 1 3 5 7 9"},{"path":"r入门-1.html","id":"函数","chapter":"第 6 部分 R入门","heading":"6.4 函数","text":"","code":""},{"path":"r入门-1.html","id":"函数的结构","chapter":"第 6 部分 R入门","heading":"6.4.1 函数的结构","text":"R 语言函数一般由三个部分构成：函数体（body），参数（formals） , 环境（environment）。可以通过相应的函数查看函数的相应部分。以常见的 “粘贴” 函数 paste() 为例：我们分别使用 body， formals, environment 函数查看 paste() 函数的相应部分。","code":"\n# paste() 函数可以将两个向量对应的元素粘贴在一起。\na <- c(\"A\",\"B\",\"C\")\nb <- c(1:3)\nc <- paste(a,b,sep = \":\",collapse = NULL)\nc## [1] \"A:1\" \"B:2\" \"C:3\"\n# 查看函数结构\nbody(paste)## .Internal(paste(list(...), sep, collapse, recycle0))\n# 查看函数参数\nformals(paste)## $...\n## \n## \n## $sep\n## [1] \" \"\n## \n## $collapse\n## NULL\n## \n## $recycle0\n## [1] FALSE\n# 查看函数来自哪个包\nenvironment(paste)## <environment: namespace:base>"},{"path":"r入门-1.html","id":"函数的功能","chapter":"第 6 部分 R入门","heading":"6.4.2 函数的功能","text":"函数就像一个加工厂，可以将 “原料” 通过一系列转变，然后输出相应的 “产品”这里的输入，可以是某个值、向量、 data.frame，或者是其他类型的数据；输出，可以是数据，文档，图片等等。","code":""},{"path":"r入门-1.html","id":"函数的分类","chapter":"第 6 部分 R入门","heading":"6.4.3 函数的分类","text":"R 语言的函数包括内置函数，外来函数（R 包），自编函数三大类。实用的内置函数实用的外来函数（tidyverse）演示（使用R自带数据）自编函数","code":"\n# 查看R语言自带数据集\ndata()\n# 描述性统计类\nsum()\ncumsum()\nmean()\nmedian()\nsd()\nquantile()\n# 生成随机数\nrunif(n = , min = , max = ) # uniform，生成 n 个服从均匀分布的小数\nround(runif(n=,min=,max=),# round() 函数空值小数点的位数\n      digits = 0)# 生成 n 个服从均匀分布的整数\n# 根据变量取值进行筛选\nfilter()\n# 选择变量\nselect()\n# 生成变量\nmutate()\n# 排序\narrange()\n# 分组统计\ngroup_by() |>\n  summarize()\n# 加载数据\ndata(\"ToothGrowth\")\n# 查看表头\ncolnames(ToothGrowth)## [1] \"len\"  \"supp\" \"dose\"\n# 查看数据结构\nstr(ToothGrowth)## 'data.frame':    60 obs. of  3 variables:\n##  $ len : num  4.2 11.5 7.3 5.8 6.4 10 11.2 11.2 5.2 7 ...\n##  $ supp: Factor w/ 2 levels \"OJ\",\"VC\": 2 2 2 2 2 2 2 2 2 2 ...\n##  $ dose: num  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ...\n# 查看分组变量的取值\nunique(ToothGrowth$supp)## [1] VC OJ\n## Levels: OJ VC\n# 生成变量（生成两个标签）\nToothGrowth <- ToothGrowth |>\n  mutate(剂量=ifelse(dose==0.5,\"0.5mg\",\n                   ifelse(dose==1.0,\"1.0mg\",\"2.0mg\"))) |>\n  mutate(补充喂养=ifelse(supp==\"VC\",\" 维 C\",\" 橙汁\"))\n\n# 分组统计\nsummary_data <- ToothGrowth |>\n  group_by(补充喂养, 剂量) |>\n  summarize(\n    n=n(),\n    mean=mean(len),\n    sd=sd(len))"},{"path":"r入门-1.html","id":"查看函数帮助","chapter":"第 6 部分 R入门","heading":"6.4.4 查看函数帮助","text":"","code":"\n# 如果知道具体的函数名字：\n? # 查看函数的帮助，比如 ?filter\nhelp() # 同？\n?? # 查看 R 包的帮助，比如??dplyr\n# 如果不知道具体的函数名字\napropos(\"norm\")# apropos: 就... 而言"},{"path":"r入门-1.html","id":"向量及其操作","chapter":"第 6 部分 R入门","heading":"6.5 向量及其操作","text":"向量为一系列标量的集合","code":""},{"path":"r入门-1.html","id":"创建向量","chapter":"第 6 部分 R入门","heading":"6.5.1 创建向量","text":"","code":"\nc()\nseq()\nrep()"},{"path":"r入门-1.html","id":"向量的类型","chapter":"第 6 部分 R入门","heading":"6.5.2 向量的类型","text":"字符串，数值， logical 类型因子类型R 语言有一类非常重要的变量类型，名为因子（factor）。因子可以视为分类变量的特殊类型，它既有值，又对值进行了排序（levels）。","code":"\n# 字符串型：\na <- c(\"A\",\"A\",\"B\",\"B\",\"C\",\"C\")\n# 数值类型\nb <- c(1:10)\n# logical 类型\nc <- c(T,T,F,F)\n# 如何生成因子\nname1 <- c(0,1,2)\nname2 <- factor(name1,\n                levels = c(0,1,2), #levels 必须与原始数据取值相同\n                labels = c(\"Male\",\"Female\",\"Both\")) #labels 是为了\nclass(name1)## [1] \"numeric\"\nclass(name2)## [1] \"factor\""},{"path":"r入门-1.html","id":"向量的运算","chapter":"第 6 部分 R入门","heading":"6.5.3 向量的运算","text":"","code":"\n# 简单统计\na <- c(1:20)\nmean(a)## [1] 10.5\n# 算数运算\nb <- 2*a # 标量与向量\nc <- b+a # 标量与向量"},{"path":"r入门-1.html","id":"重要向量的循环补齐机制","chapter":"第 6 部分 R入门","heading":"6.5.4 重要：向量的循环补齐机制","text":"","code":"\na <- c(\"A\",\"B\",\"C\",\"D\",\"E\")\nb <- c(1:3)\nc <- paste(a,b,sep = \":\")\nc## [1] \"A:1\" \"B:2\" \"C:3\" \"D:1\" \"E:2\""},{"path":"r入门-1.html","id":"交并补","chapter":"第 6 部分 R入门","heading":"6.5.5 交、并、补","text":"","code":"\n# 向量的交、并、补集，找不同，找相同，找不同（背熟）\n\n# 取交集\na <- c(1:15)\nb <- c(10:20)\nintersect(a,b) ## [1] 10 11 12 13 14 15\n# 取并集\nunion(a,b)##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17\n## [18] 18 19 20\n# 找不同\nsetdiff(a,b)## [1] 1 2 3 4 5 6 7 8 9\nsetdiff(b,a)## [1] 16 17 18 19 20\n# 去除重复\naa <- c(rep(\"A\",3),4:6)\nunique(aa)## [1] \"A\" \"4\" \"5\" \"6\""},{"path":"r入门-1.html","id":"向量的下标索引","chapter":"第 6 部分 R入门","heading":"6.5.6 向量的下标索引","text":"","code":"\n# 已经知道向量 x\nx <- c(\" 张三\",\" 小明\",\" 王五\",\" 李思齐\")\n# 如何选择李思齐？\nx[4]## [1] \" 李思齐\"\n# 如何同时选择小明与李思齐？\nx[c(2,4)]## [1] \" 小明\"   \" 李思齐\"\n# 如何不选择张三\nx[-1]## [1] \" 小明\"   \" 王五\"   \" 李思齐\""},{"path":"r入门-1.html","id":"数据框及其操作","chapter":"第 6 部分 R入门","heading":"6.6 数据框及其操作","text":"数据框是 R 语言最常用的二维表。","code":""},{"path":"r入门-1.html","id":"生成数据框","chapter":"第 6 部分 R入门","heading":"6.6.1 生成数据框","text":"","code":"\n# 通过 read.csv 函数等读取\ndf <- read_csv()\n# 通过向量组合生成\nage <- c(20,30,18,26)\nname <- c(\" 赵\",\" 钱\",\" 孙\",\" 李\")\nscore <- c(99,65,77,88)\ndf <- data.frame(age=age,\n                 name=name,\n                 score=score)"},{"path":"r入门-1.html","id":"数据框的下标索引","chapter":"第 6 部分 R入门","heading":"6.6.2 数据框的下标索引","text":"","code":"\n# 数据框下标索引中间有逗号，逗号前表示行，逗号后表示列 [row,col]\n# 选择 df 前两列\ndf[,2] # 空着表示全选## [1] \" 赵\" \" 钱\" \" 孙\" \" 李\"\ndf[2,] # 选择 df 前两行##   age name score\n## 2  30   钱    65\ndf[2,2] # 选择 df 第二行第二列## [1] \" 钱\"\ndf[-3,] # 不选择第三行##   age name score\n## 1  20   赵    99\n## 2  30   钱    65\n## 4  26   李    88\ndf[c(1,3),2] # 选择 1， 3 行； 2 列## [1] \" 赵\" \" 孙\"\ndf[df$name==\" 李\",] # 选择姓李的数据##   age name score\n## 4  26   李    88"},{"path":"r入门-1.html","id":"数据框如何生成新的列","chapter":"第 6 部分 R入门","heading":"6.6.3 数据框如何生成新的列","text":"","code":"\n# 比如生成身高数据\nheight <- c(178,180,169,175)\ndf$height <- height\ndf##   age name score height\n## 1  20   赵    99    178\n## 2  30   钱    65    180\n## 3  18   孙    77    169\n## 4  26   李    88    175"},{"path":"nhanes数据库介绍.html","id":"nhanes数据库介绍","chapter":"第 7 部分 NHANES数据库介绍","heading":"第 7 部分 NHANES数据库介绍","text":"","code":""},{"path":"nhanes数据库介绍.html","id":"数据库简介","chapter":"第 7 部分 NHANES数据库介绍","heading":"7.1 数据库简介","text":"National Health Nutrition Examination Survey （NHANES数据库，网址：https://www.cdc.gov/nchs/nhanes/index.htm）收集了有关美国家庭人口健康和营养信息，是一项基于人群的横断面调查。该数据库开始于80年代，生物样本包含了参与者的血清，血浆，尿液等，涉及多种测量指标。此外，还包含了大量的调查问卷数据，调查问卷涉及广泛，包括人口统计学、社会经济学、饮食和健康相关问题，体检部分包括生理测量、实验室检查等内容。观看NHANES官方视频介绍该数据库自20世纪末开始，每两年一个周期，更新数据，而且是免费对外开放的，研究者可以根据需要直接下载数据。在网站首页，进入Publications Products，我们可以进行交互式数据可视化展示，数据简报，电子病例等。比如，我们进入数据可视化页面的数据。这些数据代表了从1999-2000年到2017-2018年国家健康和营养检查调查 (NHANES) 的估计值。虽然NHANES数据库自带分析功能并以线图、bar图和表等展示数据，但是并不能满足我们发表论文的需求。因此，我们需要学会数据的下载和处理。当然，如何把数据库数据转化为论文，还要通过相关医学文献的阅读来实现。在NHANES数据库官网首页，点击左栏的NHANES Questionnaires, Datasets, Related Documentation，进入调查表、数据集和相关文档。待下载的数据在Continuous NHANES选项里面。这些数据是按照年份进行上传和保存的。Step 1. 点击1处或2处直接进入数据下载页面（如下图）Step 2. 可以从下图中的1、2、3处下载数据。从1或3处可以按年份下载，每个年份包含Demographics Data”（人口数据）、“Dietary Data”（饮食数据）、“Examination Data”（检查数据）、“Laboratory Data”（化验数据）、“Questionnaire Data”（问卷数据）、“Limited Access Data”（限制访问数据）。比如，我们选取2017-2018年的数据进行下载。点击选择左栏选项中的NHANES 2017-2018或右侧Continuous NHANES里面的NHANES 2017-2018。然后页面自动跳转到2017-2018数据页面。数据内容包括四部分：①数据、文档和密码文件，包含人口统计资料、饮食数据、检查资料、实验室资料、问卷表和有限访问的数据；②详细资料，包括问卷工具、实验方法、程序手册以及小册子和知情同意文件；③使用数据，包括概述、发行说明、实验室数据概览、检查资料概览、问卷数据概览、调查途径和数据分析指南、回应率和人口统计，网站还提供了网络教程。④内容概览，主要是常见问题的汇总等。点击要下载的数据文件，选择存储位置，点击下载。我们以Demographics Data为例。选择Data File下面的DEMO_J_ Data进行下载（Doc_File是对访问资料的介绍，无需下载）。文件类型是.XPT，下载时对网速有要求。下载后数据可用统计软件SPSS等打开，或者用R也可以。或者直接用nhanesA下载数据（速度可能比较慢）","code":"\nlibrary(nhanesA)\nmydata1<-nhanes('DEMO_J')"},{"path":"nhanes数据库介绍.html","id":"数据提取","chapter":"第 7 部分 NHANES数据库介绍","heading":"7.2 数据提取","text":"数据下好后用R读取对照变量说明提取需要得变量以上demo文件中只有人口统计学指标，提取其他信息还需要下载其他数据。假如我们想提取血糖，血糖应该在化验室指标那里，这次我们使用nhanesA包来下载。提取好指标后进行合并把它保存起来，今后的操作将在这个数据展开","code":"\nlibrary(haven)\nlibrary(tidyverse)\nmydata <- read_xpt(\"data/demo_j.xpt\")\nhead(mydata,10)## # A tibble: 10 × 46\n##    SEQN SDDSR…¹ RIDST…² RIAGE…³ RIDAG…⁴ RIDAG…⁵ RIDRE…⁶\n##   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n## 1 93703      10       2       2       2      NA       5\n## 2 93704      10       2       1       2      NA       3\n## 3 93705      10       2       2      66      NA       4\n## 4 93706      10       2       1      18      NA       5\n## 5 93707      10       2       1      13      NA       5\n## 6 93708      10       2       2      66      NA       5\n## # … with 4 more rows, 39 more variables:\n## #   RIDRETH3 <dbl>, RIDEXMON <dbl>, RIDEXAGM <dbl>,\n## #   DMQMILIZ <dbl>, DMQADFC <dbl>, DMDBORN4 <dbl>,\n## #   DMDCITZN <dbl>, DMDYRSUS <dbl>, DMDEDUC3 <dbl>,\n## #   DMDEDUC2 <dbl>, DMDMARTL <dbl>, RIDEXPRG <dbl>,\n## #   SIALANG <dbl>, SIAPROXY <dbl>, SIAINTRP <dbl>,\n## #   FIALANG <dbl>, FIAPROXY <dbl>, FIAINTRP <dbl>, …\ndat1<- mydata %>% select(SEQN, # 序列号\n                         RIAGENDR, # 性别\n                         RIDAGEYR, # 年龄\n                         RIDRETH3, # 种族\n                         DMDMARTL, # 婚姻状况\n                         WTINT2YR,WTMEC2YR, # 权重\n                         SDMVPSU, # psu\n                         SDMVSTRA) # strata\n# xuetang1 <- nhanes('GLU_J') # 在线提取\nxuetang <- read_xpt(\"data/glu_j.xpt\")\nknitr::kable(xuetang[1:10, ] ,align = \"c\")\nhdata<- full_join(dat1, xuetang, by = 'SEQN', type = 'full')\nknitr::kable(hdata[1:10, ] ,align = \"c\")\nwrite.csv(hdata,file= \"1.csv\",row.names = F)"},{"path":"nhanes数据库介绍.html","id":"需要注意的点","chapter":"第 7 部分 NHANES数据库介绍","heading":"7.3 需要注意的点","text":"","code":""},{"path":"nhanes数据库介绍.html","id":"结局","chapter":"第 7 部分 NHANES数据库介绍","heading":"7.3.1 结局","text":"有死亡信息，需要另外页面下载。进入死亡数据下载界面（Data Linkage——NDI Mortality Files——Public-Use Files）Public-Use Linked Mortality Files点击FTP Site，进入死亡数据索引目录。阅读数据集说明文件及变量说明，可以对数据集内容有个基本的了解。选择需要年份的死亡数据下载；","code":""},{"path":"nhanes数据库介绍.html","id":"数据分析","chapter":"第 7 部分 NHANES数据库介绍","heading":"7.3.2 数据分析","text":"NHANES是复杂抽样，所以需要用到”复杂抽样”的分析方法。并且要注意权重的合并！NHANES样本分为四个阶段：\n（）PSU（县、县内的区域组或相邻县的组合）；\n（b）PSU内的部分（普查区或区的组合）；\n（c）分段内的居住单元、家庭（DU）；\n（d）家庭中的个人。PSU是从美国所有县取样的。根据过采样标准，在DU级别进行筛选以识别被抽样的人（SP）。NHANES样本分为四个阶段：（）PSU（县、县内的区域组或相邻县的组合）；（b）PSU内的部分（普查区或区的组合）；（c）分段内的居住单元、家庭（DU）；（d）家庭中的个人。PSU是从美国所有县取样的。根据过采样标准，在DU级别进行筛选以识别被抽样的人（SP）。year:样本中年数的调整\nNHANES是每年都会进行的抽样，但由于样本量的限制，经常需要合并多年以增强统计效能。但是不同年份测量的变量不一致。比如要合并6年的数据，这可能导致有的变量2年一测，有的变量3年一测，有的变量6年一测。此时不可以直接提取进行计算。\n以4年的数据为例：由于4年样本设计，从原始抽样率计算的初始基本权重对应于4年样本。 这些初始基权值是基于抽样概率的， 为了产生与1年和2年样本的全国人口总数相一致的权重，需要调整因子。 例如，为了为2015-2016年NHANES和2017-2018年NHANES在公共使用文件中发布的数据创建两年样本权重，将4年基权重乘以2，以考虑2年的选择（设计中的年数除以样本中的年数，4除以2=2）。year:样本中年数的调整NHANES是每年都会进行的抽样，但由于样本量的限制，经常需要合并多年以增强统计效能。但是不同年份测量的变量不一致。比如要合并6年的数据，这可能导致有的变量2年一测，有的变量3年一测，有的变量6年一测。此时不可以直接提取进行计算。以4年的数据为例：由于4年样本设计，从原始抽样率计算的初始基本权重对应于4年样本。 这些初始基权值是基于抽样概率的， 为了产生与1年和2年样本的全国人口总数相一致的权重，需要调整因子。 例如，为了为2015-2016年NHANES和2017-2018年NHANES在公共使用文件中发布的数据创建两年样本权重，将4年基权重乘以2，以考虑2年的选择（设计中的年数除以样本中的年数，4除以2=2）。多看官网的各种分析提供的代码示例","code":""},{"path":"nhanes数据库介绍.html","id":"一些技巧","chapter":"第 7 部分 NHANES数据库介绍","heading":"7.3.3 一些技巧","text":"查看指定年份和指定类别的信息查看详细信息假设我们需要进一步查看BPX_J的内部信息可以看到，此表之中有27列。Seqn是受访者的序列号，可以用来连接各表。","code":"\nlibrary(nhanesA)\nnhanesTables('EXAM', 2017)\nnhanesTableVars(data_group = 'Exam', nh_table = 'BPX_J', namesonly = FALSE)"},{"path":"mimic数据库介绍.html","id":"mimic数据库介绍","chapter":"第 8 部分 MIMIC数据库介绍","heading":"第 8 部分 MIMIC数据库介绍","text":"","code":""},{"path":"mimic数据库介绍.html","id":"数据库简介-1","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.1 数据库简介","text":"","code":""},{"path":"mimic数据库介绍.html","id":"基本情况","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.1.1 基本情况","text":"MIMIC （官网：https://mimic.mit.edu/）是一个重症医学数据库，全称是Medical Information Mart Intensive Care。2003年，在NIH的资助下，来自贝斯以色列女执事医疗中心(Beth Israel Deaconess Medical Center)、麻省理工(MIT)、牛津大学和麻省总医院(MGH)的急诊科医生、重症科医生、计算机科学专家等共同建立的一个数据库。在进行隐私数据脱敏后，提供了数十万患者在急诊和ICU治疗期间基本信息（年龄、性别、基础病史），住院期间完整的诊疗信息（治疗措施、药物，生命体征、实验室检查等）以及临床结局等信息。让临床医生无需经过痛苦的收集信息的过程就可以接触到数十万患者的海量临床信息，验证自己的临床思路，发表高质量文章。","code":""},{"path":"mimic数据库介绍.html","id":"版本介绍","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.1.2 版本介绍","text":"MIMIC从开发至今，共存在三个大版本：MIMIC-II，MIMIC-III，MIMIC-IV。MIMIC-II：MIMIC-II包含2001-2008年的数据。数据是主要从CareVue监视器收集的。MIMIC-II现在已不再公开，但如果想要提取数据，可以从MIMIC-III中获取数据，利用筛选数据库来源为CareVue来提取MIMIC-II的数据。MIMIC-II：MIMIC-II包含2001-2008年的数据。数据是主要从CareVue监视器收集的。MIMIC-II现在已不再公开，但如果想要提取数据，可以从MIMIC-III中获取数据，利用筛选数据库来源为CareVue来提取MIMIC-II的数据。MIMIC-III：MIMIC-III包含2001-2012年的数据。患者数据是从Metavision和CareVue两个地方采集的。MIMIC-III 数据库当前最新版本是v1.4。这个版本是在2016年9月2日发布，此次发布提高了数据库中的数据质量，为Metavision数据库中的病人提供了大量的补充数据。MIMIC-III v1.4从2016年至今，未再进一步的修正，这也是MIMIC-III 数据库的最终版本。MIMIC-III：MIMIC-III包含2001-2012年的数据。患者数据是从Metavision和CareVue两个地方采集的。MIMIC-III 数据库当前最新版本是v1.4。这个版本是在2016年9月2日发布，此次发布提高了数据库中的数据质量，为Metavision数据库中的病人提供了大量的补充数据。MIMIC-III v1.4从2016年至今，未再进一步的修正，这也是MIMIC-III 数据库的最终版本。MIMIC-IV：MIMIC-IV是对MIMIC-III的更新，MIMIC-IV包含2008年至2019年（含）的数据。最近推出的生物标志物将可用。MIMIC-IV来自两个院内数据库系统：一个是定制的医院范围的数字电子健康记录（EHR）、一个是重症监护室（ICU）特定的临床信息系统。目前已更新到2.1版本（2022.11.16更新）。由于小版本刚更新不稳定，本次主要已2.0版本为基础进行介绍。MIMIC-IV：MIMIC-IV是对MIMIC-III的更新，MIMIC-IV包含2008年至2019年（含）的数据。最近推出的生物标志物将可用。MIMIC-IV来自两个院内数据库系统：一个是定制的医院范围的数字电子健康记录（EHR）、一个是重症监护室（ICU）特定的临床信息系统。目前已更新到2.1版本（2022.11.16更新）。由于小版本刚更新不稳定，本次主要已2.0版本为基础进行介绍。","code":""},{"path":"mimic数据库介绍.html","id":"mimic-iv创建流程","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.1.3 MIMIC-IV创建流程","text":"收购\n从各自的医院数据库中提取了入住BIDMC急诊室或其中一个重症监护病房的患者的数据。创建了一个主患者列表，其中包含与2008年至2019年期间入住ICU或急诊室的患者相对应的所有医疗记录编号。所有源表都筛选为仅与主患者列表中的患者相关的行。收购从各自的医院数据库中提取了入住BIDMC急诊室或其中一个重症监护病房的患者的数据。创建了一个主患者列表，其中包含与2008年至2019年期间入住ICU或急诊室的患者相对应的所有医疗记录编号。所有源表都筛选为仅与主患者列表中的患者相关的行。制备\n从各自的医院数据库中提取了入住BIDMC急诊室或其中一个重症监护病房的患者的数据。创建了一个主患者列表，其中包含与2008年至2019年期间入住ICU或急诊室的患者相对应的所有医疗记录编号。所有源表都筛选为仅与主患者列表中的患者相关的行。制备从各自的医院数据库中提取了入住BIDMC急诊室或其中一个重症监护病房的患者的数据。创建了一个主患者列表，其中包含与2008年至2019年期间入住ICU或急诊室的患者相对应的所有医疗记录编号。所有源表都筛选为仅与主患者列表中的患者相关的行。去识别化\nHIPAA 规定的患者标识符已被删除。使用随机密码替换患者标识符，导致患者，住院和ICU住院的整数标识符去识别化。结构化数据是使用查找表格和允许列表过滤的。如有必要，应用了自由文本去识别化算法从自由文本中删除 PHI。最后，日期和时间使用以天为单位的偏移量随机移动到将来。为每个subject_id分配了一个日期班次。因此，单个患者的数据在内部是一致的。例如，如果数据库中两个度量值之间的时间在原始数据中为4 小时，则 MIMIC-IV 中计算的时间差也将为 4 小时。相反，不同的患者在时间上不具有可比性。也就是说，2130年入院的两名患者不一定在同一年入院。去识别化HIPAA 规定的患者标识符已被删除。使用随机密码替换患者标识符，导致患者，住院和ICU住院的整数标识符去识别化。结构化数据是使用查找表格和允许列表过滤的。如有必要，应用了自由文本去识别化算法从自由文本中删除 PHI。最后，日期和时间使用以天为单位的偏移量随机移动到将来。为每个subject_id分配了一个日期班次。因此，单个患者的数据在内部是一致的。例如，如果数据库中两个度量值之间的时间在原始数据中为4 小时，则 MIMIC-IV 中计算的时间差也将为 4 小时。相反，不同的患者在时间上不具有可比性。也就是说，2130年入院的两名患者不一定在同一年入院。","code":""},{"path":"mimic数据库介绍.html","id":"mimic-iv内容组成","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.1.4 MIMIC-IV内容组成","text":"MIMIC-IV主要分为三大模块，分别是core、hosp、icu。core 模块存储使用MIMIC-IV进行任何数据分析所需的患者跟踪信息。内容包含三个表：入院表、患者表和转移表。这些表提供了患者的人口统计数据、每次住院的记录以及住院期间每个病房住宿的记录。\ncore 模块存储使用MIMIC-IV进行任何数据分析所需的患者跟踪信息。内容包含三个表：入院表、患者表和转移表。这些表提供了患者的人口统计数据、每次住院的记录以及住院期间每个病房住宿的记录。hosp 模块包含从医院范围的EHR 派生的数据。这些测量结果主要记录在住院期间，尽管有些表格也包括来自医院外的数据（例如，在实验室活动中进行的门诊实验室检查）。信息包括实验室测量、微生物培养、提供者订单、药物管理、药物处方、医院账单信息和服务相关信息。\nhosp 模块包含从医院范围的EHR 派生的数据。这些测量结果主要记录在住院期间，尽管有些表格也包括来自医院外的数据（例如，在实验室活动中进行的门诊实验室检查）。信息包括实验室测量、微生物培养、提供者订单、药物管理、药物处方、医院账单信息和服务相关信息。icu 模块包含来自BIDMC：MetaVision（iMDSoft）的临床信息系统的数据。MetaVision表被非规范化以创建一个星形架构，其中icustays和d_items表链接到一组数据表，所有数据表都以”事件”为后缀。icu模块中记录的数据包括静脉注射和液体输入（输入事件）、患者输出（输出事件）、程序（程序事件）、记录为日期或时间的信息（日期时间事件）以及其他图表信息（图表事件）。所有事件表都包含一个stay_id列，用于识别icustays中的相关ICU患者，以及一个允许识别d_items中记录的概念的 itemid 列。\nicu 模块包含来自BIDMC：MetaVision（iMDSoft）的临床信息系统的数据。MetaVision表被非规范化以创建一个星形架构，其中icustays和d_items表链接到一组数据表，所有数据表都以”事件”为后缀。icu模块中记录的数据包括静脉注射和液体输入（输入事件）、患者输出（输出事件）、程序（程序事件）、记录为日期或时间的信息（日期时间事件）以及其他图表信息（图表事件）。所有事件表都包含一个stay_id列，用于识别icustays中的相关ICU患者，以及一个允许识别d_items中记录的概念的 itemid 列。数据总览\n数据总览","code":""},{"path":"mimic数据库介绍.html","id":"数据库申请","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.2 数据库申请","text":"","code":""},{"path":"mimic数据库介绍.html","id":"注册physionet账号","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.2.1 注册Physionet账号","text":"进入网址：www.physionet.org，注册账号。\n建议使用机构/学校邮箱申请，注册后邮箱会收到激活账号链接，点击网址激活。进入网址：www.physionet.org，注册账号。建议使用机构/学校邮箱申请，注册后邮箱会收到激活账号链接，点击网址激活。登录后选设置然后点Credentialing，apply access就会提示你为了获得认证，需要通过相关培训认证，培训认证，是在CITI这个网站提供的。","code":""},{"path":"mimic数据库介绍.html","id":"注册citi账号","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.2.2 注册CITI账号","text":"①复制这句话：“Massachusetts Institute Technology Affiliates”，表示是MIT附属单位，这样才能免费获取课程。②在Physionet网页上点击或者直接访问（https://.citiprogram.org），注意要贴上之前复制的文字。注册完成，登录进去就可以看到课程。两个都考第一门有两个模块，第二门有九个模块。考试可反复参加，90%以上正确率才合格，完成考试后需下载报告。部分试题答案：followingproposed studies constitute human subjects research defined thefederal regulations?researcher school social workobtains access students’ academic records (including identifiableinformation) assess effect drug awareness programs studentacademic achievement. followingactivities meets federal definitions research?Collection elementary school test scoresto evaluate effectiveness experimental program teach reading followingconstitutes breach confidentiality (research data beendisclosed, counter agreement researcher subjects) aviolation subjects’ privacy (right individuals protectedagainst intrusion personal lives affairs)?faculty member makes identifiable dataabout sexual behavior available graduate students, although subjectswere assured data de-identified. following isa measure researchers can use protect confidentiality subject data?Keep sensitive identifiable data inencrypted files password protected hard drive. primarypotential harm breach individually identifiable data, protectagainst disclosure researcher .Encrypt data store passwordprotected files. followingstatements individually identifiable research data correct?Researchers may required releaseindividually identifiable information outside research setting. followingresearch activities children qualifies exemption?researcher observing children aplayground identify bullying behaviors. accordance withfederal regulations, following statements best describes whenresearch children may exempt?certain exemption categories can beused research involving children. followingactivities constitutes engagement research?Obtaining informed consent conductingresearch interviews. federally fundedresearch involves collaboration organization ”engaged” research foreign country, foreign organizationcan rely US researcher’s institution’s IRB review. followingpractices example principle beneficence applied astudy involving human subjects?Ensuring risks reasonable inrelationship anticipated benefits. researcher fails toinform subjects risks benefits focus group. Whichof following describes ethical principle violated researcher?Respect persons evaluating risks ofharm IRBs must determine :isks reasonable relation toanticipated benefits. According criteriafor IRB approval, considering equitable treatment subjects, specialcare must taken following populations?prisoners statement iscorrect informed consent?requires disclosure benefits tothe subject others may reasonably expected informed consentdocument, regardless research topic, must always include following:statement describing extent, ,confidentiality records identifying subject maintained. graduate student inCommunications intends write thesis, part federally-fundedstudy, effect print versus televised media people’s daily lives.researcher wishes conduct study local prison limitedresources subject recruitment. subjects asked 15 minutes oftheir time. questionnaire appears innocuous risks appear beminimal. IRB :approve project theresearch question answered without participation prisoners. researcher wishes toconduct study relationship paternal care giving (, thecare prisoner subjects received children fathers) andincarceration, using short 15-minute survey. category applies thisresearch?Study possible causes, effects, andprocesses incarceration, criminal behavior, provided studypresents minimal risk inconvenience thesubjects (Category )Comment Providing parentsinformation study, lieu active parental permission, allowedwhen:IRB approved waiver therequirement parental permission research isconducted educational settings children, assent ofpotential student subjects required?IRB determined studentsare capable providing assent.","code":""},{"path":"mimic数据库介绍.html","id":"上传成绩单及个人信息等待人工审核","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.2.3 上传成绩单及个人信息，等待人工审核","text":"考试通过后，回到Physionet，acount，credentialing那里，把所有的信息都填上，上传CITI的成绩单，提交申请，等待通过，注意Reference这里一定要认真填写，邮箱要正确。等待…..邮件通知通过注册。","code":""},{"path":"mimic数据库介绍.html","id":"通过后签署同意书下载数据","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.2.4 通过后签署同意书，下载数据","text":"审核通过后，就可以在Physionet首页，Data这里点击进去，下载数据，你会看到，除了MIMIC以外，这里还有好多其他数据集。","code":""},{"path":"mimic数据库介绍.html","id":"数据库下载与安装","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.3 数据库下载与安装","text":"","code":""},{"path":"mimic数据库介绍.html","id":"数据下载","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.3.1 数据下载","text":"通过注册后，进入https://physionet.org/content/mimiciv/2.0/ 签署知情同意正常是在Files有一个下载的链接：但是由于版本更新，2.0目前无下载链接。所以使用我提供的数据进行演练（仅供内部练习使用，没有获得权限无法发表文章）百度云地址：（留好足够空间，建议80G以上）https://pan.baidu.com/s/1FMYJh4IFuqMpH1f69OuJXw?pwd=ed5c提取码：ed5c","code":""},{"path":"mimic数据库介绍.html","id":"数据安装","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.3.2 数据安装","text":"","code":""},{"path":"mimic数据库介绍.html","id":"官方教程的安装","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.3.2.1 官方教程的安装","text":"安装比较难….流程都一样，但会出现各种莫名奇妙的问题，推荐几个安装教程，大家自己尝试下。MIMIC-IV数据库安装过程更简化（电脑小白保姆版）手把手教你MIMIC-IV数据库安装前方有雷！MIMIC-IV数据库安装排雷指南智慧ICU我们再次进入mimic官网（https://mimic.physionet.org/gettingstarted/access/）我们再次进入mimic官网（https://mimic.physionet.org/gettingstarted/access/）点击getting started，拉到下面点击 Local database setup\n点击getting started，拉到下面点击 Local database setup按照教程页面安装PostgreSQL、7-zip，随后在命令框输入教程代码进行配置数据库即可。\n按照教程页面安装PostgreSQL、7-zip，随后在命令框输入教程代码进行配置数据库即可。","code":""},{"path":"mimic数据库介绍.html","id":"navicat-的安装","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.3.2.2 Navicat 的安装","text":"按照官方教程安装完成后，下面再进行安装Navicat软件，官网提供14天免费的试用功能。大家可以下载安装（提供的百度云链接里也有安装包）。打开Navicat，点击连接-PostgreSQL，如下图；进入如下界面，在连接名里随意输入名称，密码填之前设置的超级管理员postgres的密码；点击确定，连接成功，这是可在左侧看到我们连接到的mimic iv数据库。观看<科研杂录>安装教程","code":""},{"path":"mimic数据库介绍.html","id":"数据提取-1","chapter":"第 8 部分 MIMIC数据库介绍","heading":"8.4 数据提取","text":"","code":""}]
